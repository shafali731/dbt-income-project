2021-02-15 01:49:01.065808 (MainThread): Running with dbt=0.19.0
2021-02-15 01:49:02.828826 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/shafaligupta/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-02-15 01:49:02.833892 (MainThread): Tracking: tracking
2021-02-15 01:49:02.851006 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110bdab20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110bea220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110bea100>]}
2021-02-15 01:49:02.927199 (MainThread): Partial parsing not enabled
2021-02-15 01:49:02.935041 (MainThread): Parsing macros/etc.sql
2021-02-15 01:49:02.946473 (MainThread): Parsing macros/catalog.sql
2021-02-15 01:49:02.967897 (MainThread): Parsing macros/adapters.sql
2021-02-15 01:49:03.025745 (MainThread): Parsing macros/materializations/seed.sql
2021-02-15 01:49:03.038826 (MainThread): Parsing macros/materializations/view.sql
2021-02-15 01:49:03.049410 (MainThread): Parsing macros/materializations/table.sql
2021-02-15 01:49:03.077137 (MainThread): Parsing macros/materializations/copy.sql
2021-02-15 01:49:03.089287 (MainThread): Parsing macros/materializations/incremental.sql
2021-02-15 01:49:03.134637 (MainThread): Parsing macros/materializations/snapshot.sql
2021-02-15 01:49:03.147257 (MainThread): Parsing macros/core.sql
2021-02-15 01:49:03.157296 (MainThread): Parsing macros/materializations/helpers.sql
2021-02-15 01:49:03.176672 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-02-15 01:49:03.182644 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-02-15 01:49:03.220261 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-02-15 01:49:03.298396 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-02-15 01:49:03.344051 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-02-15 01:49:03.348746 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-02-15 01:49:03.360175 (MainThread): Parsing macros/materializations/common/merge.sql
2021-02-15 01:49:03.386112 (MainThread): Parsing macros/materializations/table/table.sql
2021-02-15 01:49:03.399500 (MainThread): Parsing macros/materializations/view/view.sql
2021-02-15 01:49:03.411120 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-02-15 01:49:03.421413 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-02-15 01:49:03.424397 (MainThread): Parsing macros/etc/query.sql
2021-02-15 01:49:03.427885 (MainThread): Parsing macros/etc/is_incremental.sql
2021-02-15 01:49:03.432903 (MainThread): Parsing macros/etc/datetime.sql
2021-02-15 01:49:03.449802 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-02-15 01:49:03.456828 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-02-15 01:49:03.461273 (MainThread): Parsing macros/adapters/common.sql
2021-02-15 01:49:03.583325 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-02-15 01:49:03.591616 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-02-15 01:49:03.596998 (MainThread): Parsing macros/schema_tests/unique.sql
2021-02-15 01:49:03.603976 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-02-15 01:49:03.640934 (MainThread): Partial parsing not enabled
2021-02-15 01:49:03.818787 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.my_first_dbt_model".
2021-02-15 01:49:03.892604 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.my_second_dbt_model".
2021-02-15 01:49:04.500550 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '75a67c2c-11fd-49a4-8a27-ab48fa6d706d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110ecf3d0>]}
2021-02-15 01:49:04.601564 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-02-15 01:49:04.602787 (MainThread): 
2021-02-15 01:49:04.603325 (MainThread): Acquiring new bigquery connection "master".
2021-02-15 01:49:04.607522 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_dbt-income".
2021-02-15 01:49:04.608920 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-02-15 01:49:04.951375 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_dbt-income_dbt_shafali".
2021-02-15 01:49:04.952343 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_dbt-income_dbt_shafali".
2021-02-15 01:49:04.952838 (ThreadPoolExecutor-0_0): Creating schema "dbt-income.dbt_shafali".
2021-02-15 01:49:04.954592 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-02-15 01:49:04.963196 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-02-15 01:49:05.850122 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_dbt-income_dbt_shafali".
2021-02-15 01:49:05.850767 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-02-15 01:49:05.857680 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-02-15 01:49:06.216931 (MainThread): 20:49:06 | Concurrency: 1 threads (target='dev')
2021-02-15 01:49:06.217412 (MainThread): 20:49:06 | 
2021-02-15 01:49:06.226024 (Thread-1): Began running node model.dbt_income_project.my_first_dbt_model
2021-02-15 01:49:06.230478 (Thread-1): 20:49:06 | 1 of 2 START table model dbt_shafali.my_first_dbt_model.............. [RUN]
2021-02-15 01:49:06.230983 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.my_first_dbt_model".
2021-02-15 01:49:06.231184 (Thread-1): Compiling model.dbt_income_project.my_first_dbt_model
2021-02-15 01:49:06.322350 (Thread-1): Writing injected SQL for node "model.dbt_income_project.my_first_dbt_model"
2021-02-15 01:49:06.339998 (Thread-1): finished collecting timing info
2021-02-15 01:49:06.371752 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 50677), raddr=('172.217.165.138', 443)>
2021-02-15 01:49:06.374522 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 50678), raddr=('172.217.11.42', 443)>
2021-02-15 01:49:06.375459 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 50680), raddr=('172.217.11.42', 443)>
2021-02-15 01:49:06.377089 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 50679), raddr=('172.217.165.138', 443)>
2021-02-15 01:49:06.384463 (Thread-1): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 50683), raddr=('172.217.11.42', 443)>
2021-02-15 01:49:06.386878 (Thread-1): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 50682), raddr=('172.217.165.138', 443)>
2021-02-15 01:49:06.873568 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.my_first_dbt_model"
2021-02-15 01:49:06.875336 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 01:49:06.885693 (Thread-1): On model.dbt_income_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.my_first_dbt_model"} */


  create or replace table `dbt-income`.`dbt_shafali`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-02-15 01:49:08.942355 (Thread-1): finished collecting timing info
2021-02-15 01:49:08.943972 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '75a67c2c-11fd-49a4-8a27-ab48fa6d706d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110dbbfd0>]}
2021-02-15 01:49:08.952237 (Thread-1): 20:49:08 | 1 of 2 OK created table model dbt_shafali.my_first_dbt_model......... [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 2.71s]
2021-02-15 01:49:08.952728 (Thread-1): Finished running node model.dbt_income_project.my_first_dbt_model
2021-02-15 01:49:08.953672 (Thread-1): Began running node model.dbt_income_project.my_second_dbt_model
2021-02-15 01:49:08.958780 (Thread-1): 20:49:08 | 2 of 2 START view model dbt_shafali.my_second_dbt_model.............. [RUN]
2021-02-15 01:49:08.959703 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.my_second_dbt_model".
2021-02-15 01:49:08.959971 (Thread-1): Compiling model.dbt_income_project.my_second_dbt_model
2021-02-15 01:49:08.992918 (Thread-1): Writing injected SQL for node "model.dbt_income_project.my_second_dbt_model"
2021-02-15 01:49:08.993778 (Thread-1): finished collecting timing info
2021-02-15 01:49:09.064962 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.my_second_dbt_model"
2021-02-15 01:49:09.066324 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 01:49:09.078350 (Thread-1): On model.dbt_income_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.my_second_dbt_model"} */


  create or replace view `dbt-income`.`dbt_shafali`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `dbt-income`.`dbt_shafali`.`my_first_dbt_model`
where id = 1;


2021-02-15 01:49:10.172794 (Thread-1): finished collecting timing info
2021-02-15 01:49:10.174483 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '75a67c2c-11fd-49a4-8a27-ab48fa6d706d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e1f940>]}
2021-02-15 01:49:10.177362 (Thread-1): 20:49:10 | 2 of 2 OK created view model dbt_shafali.my_second_dbt_model......... [OK in 1.21s]
2021-02-15 01:49:10.177726 (Thread-1): Finished running node model.dbt_income_project.my_second_dbt_model
2021-02-15 01:49:10.182145 (MainThread): Acquiring new bigquery connection "master".
2021-02-15 01:49:10.183516 (MainThread): 20:49:10 | 
2021-02-15 01:49:10.183976 (MainThread): 20:49:10 | Finished running 1 table model, 1 view model in 5.58s.
2021-02-15 01:49:10.184403 (MainThread): Connection 'master' was properly closed.
2021-02-15 01:49:10.184730 (MainThread): Connection 'model.dbt_income_project.my_second_dbt_model' was properly closed.
2021-02-15 01:49:10.295114 (MainThread): 
2021-02-15 01:49:10.295713 (MainThread): Completed successfully
2021-02-15 01:49:10.296132 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-02-15 01:49:10.296679 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c43610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110eee8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110eee160>]}
2021-02-15 01:49:10.297657 (MainThread): Flushing usage events
2021-02-15 02:12:40.814606 (MainThread): Running with dbt=0.19.0
2021-02-15 02:12:42.060075 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/shafaligupta/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-02-15 02:12:42.063296 (MainThread): Tracking: tracking
2021-02-15 02:12:42.078345 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1bb5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d1c7d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d1c7c10>]}
2021-02-15 02:12:42.126130 (MainThread): Partial parsing not enabled
2021-02-15 02:12:42.128840 (MainThread): Parsing macros/etc.sql
2021-02-15 02:12:42.136951 (MainThread): Parsing macros/catalog.sql
2021-02-15 02:12:42.150529 (MainThread): Parsing macros/adapters.sql
2021-02-15 02:12:42.195930 (MainThread): Parsing macros/materializations/seed.sql
2021-02-15 02:12:42.202455 (MainThread): Parsing macros/materializations/view.sql
2021-02-15 02:12:42.209329 (MainThread): Parsing macros/materializations/table.sql
2021-02-15 02:12:42.237422 (MainThread): Parsing macros/materializations/copy.sql
2021-02-15 02:12:42.246999 (MainThread): Parsing macros/materializations/incremental.sql
2021-02-15 02:12:42.272736 (MainThread): Parsing macros/materializations/snapshot.sql
2021-02-15 02:12:42.287690 (MainThread): Parsing macros/core.sql
2021-02-15 02:12:42.300580 (MainThread): Parsing macros/materializations/helpers.sql
2021-02-15 02:12:42.317372 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-02-15 02:12:42.321896 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-02-15 02:12:42.357264 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-02-15 02:12:42.416187 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-02-15 02:12:42.454763 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-02-15 02:12:42.459786 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-02-15 02:12:42.476482 (MainThread): Parsing macros/materializations/common/merge.sql
2021-02-15 02:12:42.502331 (MainThread): Parsing macros/materializations/table/table.sql
2021-02-15 02:12:42.515896 (MainThread): Parsing macros/materializations/view/view.sql
2021-02-15 02:12:42.529686 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-02-15 02:12:42.542898 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-02-15 02:12:42.545858 (MainThread): Parsing macros/etc/query.sql
2021-02-15 02:12:42.555045 (MainThread): Parsing macros/etc/is_incremental.sql
2021-02-15 02:12:42.560101 (MainThread): Parsing macros/etc/datetime.sql
2021-02-15 02:12:42.578115 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-02-15 02:12:42.584348 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-02-15 02:12:42.588403 (MainThread): Parsing macros/adapters/common.sql
2021-02-15 02:12:42.657225 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-02-15 02:12:42.663171 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-02-15 02:12:42.670119 (MainThread): Parsing macros/schema_tests/unique.sql
2021-02-15 02:12:42.675906 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-02-15 02:12:42.693348 (MainThread): Partial parsing not enabled
2021-02-15 02:12:42.760502 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.my_first_dbt_model".
2021-02-15 02:12:42.794012 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.my_second_dbt_model".
2021-02-15 02:12:42.813543 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_median_and_mean_US".
2021-02-15 02:12:43.241718 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7a4bc8d3-0635-421d-8942-dca4853fc794', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d4bcd00>]}
2021-02-15 02:12:43.320604 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-02-15 02:12:43.321791 (MainThread): 
2021-02-15 02:12:43.322281 (MainThread): Acquiring new bigquery connection "master".
2021-02-15 02:12:43.328030 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_dbt-income".
2021-02-15 02:12:43.328395 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-02-15 02:12:43.742014 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_dbt-income_dbt_shafali".
2021-02-15 02:12:43.742547 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-02-15 02:12:43.752394 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-02-15 02:12:44.113251 (MainThread): 21:12:44 | Concurrency: 1 threads (target='dev')
2021-02-15 02:12:44.113575 (MainThread): 21:12:44 | 
2021-02-15 02:12:44.117402 (Thread-1): Began running node model.dbt_income_project.my_first_dbt_model
2021-02-15 02:12:44.120119 (Thread-1): 21:12:44 | 1 of 3 START table model dbt_shafali.my_first_dbt_model.............. [RUN]
2021-02-15 02:12:44.120881 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.my_first_dbt_model".
2021-02-15 02:12:44.121180 (Thread-1): Compiling model.dbt_income_project.my_first_dbt_model
2021-02-15 02:12:44.188111 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51147), raddr=('172.217.6.202', 443)>
2021-02-15 02:12:44.190113 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51149), raddr=('172.217.11.42', 443)>
2021-02-15 02:12:44.191189 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51151), raddr=('172.217.11.42', 443)>
2021-02-15 02:12:44.192128 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51150), raddr=('172.217.6.202', 443)>
2021-02-15 02:12:44.204208 (Thread-1): Writing injected SQL for node "model.dbt_income_project.my_first_dbt_model"
2021-02-15 02:12:44.205237 (Thread-1): finished collecting timing info
2021-02-15 02:12:44.249279 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:12:44.274504 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-02-15 02:12:44.573799 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.my_first_dbt_model"
2021-02-15 02:12:44.574507 (Thread-1): On model.dbt_income_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.my_first_dbt_model"} */


  create or replace table `dbt-income`.`dbt_shafali`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-02-15 02:12:46.323399 (Thread-1): finished collecting timing info
2021-02-15 02:12:46.324608 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a4bc8d3-0635-421d-8942-dca4853fc794', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d5aa7f0>]}
2021-02-15 02:12:46.326200 (Thread-1): 21:12:46 | 1 of 3 OK created table model dbt_shafali.my_first_dbt_model......... [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 2.20s]
2021-02-15 02:12:46.326430 (Thread-1): Finished running node model.dbt_income_project.my_first_dbt_model
2021-02-15 02:12:46.326786 (Thread-1): Began running node model.dbt_income_project.acs_median_and_mean_US
2021-02-15 02:12:46.328238 (Thread-1): 21:12:46 | 2 of 3 START view model dbt_shafali.acs_median_and_mean_US........... [RUN]
2021-02-15 02:12:46.329001 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.acs_median_and_mean_US".
2021-02-15 02:12:46.329231 (Thread-1): Compiling model.dbt_income_project.acs_median_and_mean_US
2021-02-15 02:12:46.337964 (Thread-1): Writing injected SQL for node "model.dbt_income_project.acs_median_and_mean_US"
2021-02-15 02:12:46.338774 (Thread-1): finished collecting timing info
2021-02-15 02:12:46.374649 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.acs_median_and_mean_US"
2021-02-15 02:12:46.375644 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:12:46.380945 (Thread-1): On model.dbt_income_project.acs_median_and_mean_US: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.acs_median_and_mean_US"} */


  create or replace view `dbt-income`.`dbt_shafali`.`acs_median_and_mean_US`
  OPTIONS()
  as # geo_id, income_2018
WITH acs_2018 AS (
    SELECT
        geo_id,
        median_income AS income_2018,
    FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
  ),
#median_income_us
median_income_in_us_2018 AS(
    SELECT
    region, MAX(median) as median_income_in_US_2018
    FROM(
        SELECT "US" AS region,
        PERCENTILE_CONT( median_income, 0.5) 
            OVER ()AS median
        FROM bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr
    )
    AS tmp
    GROUP BY region
),
#mean_income_us
mean_income_in_us_2018 AS(
    SELECT 
     "US" AS region,AVG(median_income) AS mean_income_in_us_2018
     FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
),
acs_2018_with_statecode AS (
    SELECT
        geo_id,
        income_2018,
        geo.state_code
    FROM
        acs_2018 a18
    JOIN
        `bigquery-public-data.geo_us_boundaries.zip_codes` geo
    ON
        a18.geo_id = geo.zip_code 
    WHERE geo.state_code = 'NY' OR geo.state_code = 'CA' OR geo.state_code = 'TX' OR geo.state_code = 'FL'
),
#state median income
median_income_state_2018 AS(
    SELECT
    state_code, MAX(median) as median_income_2018
    FROM(
        SELECT state_code,
        PERCENTILE_CONT( income_2018, 0.5) 
            OVER (PARTITION BY state_code)AS median
        FROM acs_2018_with_statecode
    )
    AS tmp
    GROUP BY state_code
),
#state mean income
mean_income_state_2018 AS(
    SELECT
    state_code,
     AVG(income_2018) AS mean_income_in_2018,
    FROM
    acs_2018_with_statecode
    GROUP BY
    state_code
),
# states median + mean 
mean_median_income_state_2018 AS(
    SELECT mean_income_state_2018.state_code, mean_income_in_2018, median_income_state_2018.median_income_2018 FROM mean_income_state_2018 
    INNER JOIN  median_income_state_2018 
    ON mean_income_state_2018.state_code = median_income_state_2018.state_code
),
# US median + mean 
mean_median_income_us_2018 AS(
    SELECT median_income_in_us_2018.region,mean_income_in_us_2018.mean_income_in_US_2018, median_income_in_us_2018.median_income_in_US_2018 FROM median_income_in_us_2018 
    INNER JOIN  mean_income_in_us_2018  
    ON mean_income_in_us_2018.region = median_income_in_us_2018.region
),
state_us_mean_median_income_2018 AS(
    SELECT region, mean_income_in_US_2018, median_income_in_US_2018 
    FROM mean_median_income_us_2018
    UNION ALL
    SELECT state_code, mean_income_in_2018, median_income_2018
    FROM 
    mean_median_income_state_2018
)
SELECT * FROM state_us_mean_median_income_2018;;


2021-02-15 02:12:46.895886 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/dbt-income/queries/78ebcf97-11b3-4863-a1d2-97c3d00640cd?maxResults=0&location=US&prettyPrint=false: Syntax error: Expected end of input but got ";" at [90:48]')
2021-02-15 02:12:47.388410 (Thread-1): finished collecting timing info
2021-02-15 02:12:47.389609 (Thread-1): Database Error in model acs_median_and_mean_US (models/exercise1/acs_median_and_mean_US.sql)
  Syntax error: Expected end of input but got ";" at [90:48]
  compiled SQL at target/run/dbt_income_project/models/exercise1/acs_median_and_mean_US.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/dbt-income/queries/9b1c6078-82b5-42fb-9d67-c52e7466a9ec?maxResults=0&location=US&prettyPrint=false: Syntax error: Expected end of input but got ";" at [90:48]

(job ID: 9b1c6078-82b5-42fb-9d67-c52e7466a9ec)

                                                                        -----Query Job SQL Follows-----                                                                        

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.acs_median_and_mean_US"} */
   2:
   3:
   4:  create or replace view `dbt-income`.`dbt_shafali`.`acs_median_and_mean_US`
   5:  OPTIONS()
   6:  as # geo_id, income_2018
   7:WITH acs_2018 AS (
   8:    SELECT
   9:        geo_id,
  10:        median_income AS income_2018,
  11:    FROM
  12:        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
  13:  ),
  14:#median_income_us
  15:median_income_in_us_2018 AS(
  16:    SELECT
  17:    region, MAX(median) as median_income_in_US_2018
  18:    FROM(
  19:        SELECT "US" AS region,
  20:        PERCENTILE_CONT( median_income, 0.5) 
  21:            OVER ()AS median
  22:        FROM bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr
  23:    )
  24:    AS tmp
  25:    GROUP BY region
  26:),
  27:#mean_income_us
  28:mean_income_in_us_2018 AS(
  29:    SELECT 
  30:     "US" AS region,AVG(median_income) AS mean_income_in_us_2018
  31:     FROM
  32:        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
  33:),
  34:acs_2018_with_statecode AS (
  35:    SELECT
  36:        geo_id,
  37:        income_2018,
  38:        geo.state_code
  39:    FROM
  40:        acs_2018 a18
  41:    JOIN
  42:        `bigquery-public-data.geo_us_boundaries.zip_codes` geo
  43:    ON
  44:        a18.geo_id = geo.zip_code 
  45:    WHERE geo.state_code = 'NY' OR geo.state_code = 'CA' OR geo.state_code = 'TX' OR geo.state_code = 'FL'
  46:),
  47:#state median income
  48:median_income_state_2018 AS(
  49:    SELECT
  50:    state_code, MAX(median) as median_income_2018
  51:    FROM(
  52:        SELECT state_code,
  53:        PERCENTILE_CONT( income_2018, 0.5) 
  54:            OVER (PARTITION BY state_code)AS median
  55:        FROM acs_2018_with_statecode
  56:    )
  57:    AS tmp
  58:    GROUP BY state_code
  59:),
  60:#state mean income
  61:mean_income_state_2018 AS(
  62:    SELECT
  63:    state_code,
  64:     AVG(income_2018) AS mean_income_in_2018,
  65:    FROM
  66:    acs_2018_with_statecode
  67:    GROUP BY
  68:    state_code
  69:),
  70:# states median + mean 
  71:mean_median_income_state_2018 AS(
  72:    SELECT mean_income_state_2018.state_code, mean_income_in_2018, median_income_state_2018.median_income_2018 FROM mean_income_state_2018 
  73:    INNER JOIN  median_income_state_2018 
  74:    ON mean_income_state_2018.state_code = median_income_state_2018.state_code
  75:),
  76:# US median + mean 
  77:mean_median_income_us_2018 AS(
  78:    SELECT median_income_in_us_2018.region,mean_income_in_us_2018.mean_income_in_US_2018, median_income_in_us_2018.median_income_in_US_2018 FROM median_income_in_us_2018 
  79:    INNER JOIN  mean_income_in_us_2018  
  80:    ON mean_income_in_us_2018.region = median_income_in_us_2018.region
  81:),
  82:state_us_mean_median_income_2018 AS(
  83:    SELECT region, mean_income_in_US_2018, median_income_in_US_2018 
  84:    FROM mean_median_income_us_2018
  85:    UNION ALL
  86:    SELECT state_code, mean_income_in_2018, median_income_2018
  87:    FROM 
  88:    mean_median_income_state_2018
  89:)
  90:SELECT * FROM state_us_mean_median_income_2018;;
  91:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/Cellar/python@3.8/3.8.7_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model acs_median_and_mean_US (models/exercise1/acs_median_and_mean_US.sql)
  Syntax error: Expected end of input but got ";" at [90:48]
  compiled SQL at target/run/dbt_income_project/models/exercise1/acs_median_and_mean_US.sql
2021-02-15 02:12:47.435216 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a4bc8d3-0635-421d-8942-dca4853fc794', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d6446d0>]}
2021-02-15 02:12:47.437144 (Thread-1): 21:12:47 | 2 of 3 ERROR creating view model dbt_shafali.acs_median_and_mean_US.. [ERROR in 1.11s]
2021-02-15 02:12:47.437503 (Thread-1): Finished running node model.dbt_income_project.acs_median_and_mean_US
2021-02-15 02:12:47.438053 (Thread-1): Began running node model.dbt_income_project.my_second_dbt_model
2021-02-15 02:12:47.439967 (Thread-1): 21:12:47 | 3 of 3 START view model dbt_shafali.my_second_dbt_model.............. [RUN]
2021-02-15 02:12:47.440868 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.my_second_dbt_model".
2021-02-15 02:12:47.441083 (Thread-1): Compiling model.dbt_income_project.my_second_dbt_model
2021-02-15 02:12:47.459179 (Thread-1): Writing injected SQL for node "model.dbt_income_project.my_second_dbt_model"
2021-02-15 02:12:47.459832 (Thread-1): finished collecting timing info
2021-02-15 02:12:47.467536 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.my_second_dbt_model"
2021-02-15 02:12:47.468435 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:12:47.475209 (Thread-1): On model.dbt_income_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.my_second_dbt_model"} */


  create or replace view `dbt-income`.`dbt_shafali`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `dbt-income`.`dbt_shafali`.`my_first_dbt_model`
where id = 1;


2021-02-15 02:12:48.356007 (Thread-1): finished collecting timing info
2021-02-15 02:12:48.359264 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a4bc8d3-0635-421d-8942-dca4853fc794', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d66d1c0>]}
2021-02-15 02:12:48.362410 (Thread-1): 21:12:48 | 3 of 3 OK created view model dbt_shafali.my_second_dbt_model......... [OK in 0.92s]
2021-02-15 02:12:48.362995 (Thread-1): Finished running node model.dbt_income_project.my_second_dbt_model
2021-02-15 02:12:48.365329 (MainThread): Acquiring new bigquery connection "master".
2021-02-15 02:12:48.366265 (MainThread): 21:12:48 | 
2021-02-15 02:12:48.366664 (MainThread): 21:12:48 | Finished running 1 table model, 2 view models in 5.04s.
2021-02-15 02:12:48.367148 (MainThread): Connection 'master' was properly closed.
2021-02-15 02:12:48.367406 (MainThread): Connection 'model.dbt_income_project.my_second_dbt_model' was properly closed.
2021-02-15 02:12:48.445485 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51154), raddr=('172.217.11.42', 443)>
2021-02-15 02:12:48.446076 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51153), raddr=('172.217.6.202', 443)>
2021-02-15 02:12:48.446606 (MainThread): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51156), raddr=('172.217.6.202', 443)>
2021-02-15 02:12:48.447187 (MainThread): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51157), raddr=('172.217.11.42', 443)>
2021-02-15 02:12:48.447852 (MainThread): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51161), raddr=('172.217.11.42', 443)>
2021-02-15 02:12:48.448332 (MainThread): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51160), raddr=('172.217.6.202', 443)>
2021-02-15 02:12:48.457176 (MainThread): 
2021-02-15 02:12:48.457424 (MainThread): Completed with 1 error and 0 warnings:
2021-02-15 02:12:48.457725 (MainThread): 
2021-02-15 02:12:48.458305 (MainThread): Database Error in model acs_median_and_mean_US (models/exercise1/acs_median_and_mean_US.sql)
2021-02-15 02:12:48.458627 (MainThread):   Syntax error: Expected end of input but got ";" at [90:48]
2021-02-15 02:12:48.459002 (MainThread):   compiled SQL at target/run/dbt_income_project/models/exercise1/acs_median_and_mean_US.sql
2021-02-15 02:12:48.459486 (MainThread): 
Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
2021-02-15 02:12:48.459991 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d57b580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d4cc670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d4ef340>]}
2021-02-15 02:12:48.460314 (MainThread): Flushing usage events
2021-02-15 02:13:35.882699 (MainThread): Running with dbt=0.19.0
2021-02-15 02:13:37.052367 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/shafaligupta/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-02-15 02:13:37.055649 (MainThread): Tracking: tracking
2021-02-15 02:13:37.068248 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119575e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a8baf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a8b9d0>]}
2021-02-15 02:13:37.113120 (MainThread): Partial parsing not enabled
2021-02-15 02:13:37.116149 (MainThread): Parsing macros/etc.sql
2021-02-15 02:13:37.122555 (MainThread): Parsing macros/catalog.sql
2021-02-15 02:13:37.140042 (MainThread): Parsing macros/adapters.sql
2021-02-15 02:13:37.186802 (MainThread): Parsing macros/materializations/seed.sql
2021-02-15 02:13:37.193890 (MainThread): Parsing macros/materializations/view.sql
2021-02-15 02:13:37.200422 (MainThread): Parsing macros/materializations/table.sql
2021-02-15 02:13:37.217997 (MainThread): Parsing macros/materializations/copy.sql
2021-02-15 02:13:37.227400 (MainThread): Parsing macros/materializations/incremental.sql
2021-02-15 02:13:37.248995 (MainThread): Parsing macros/materializations/snapshot.sql
2021-02-15 02:13:37.256212 (MainThread): Parsing macros/core.sql
2021-02-15 02:13:37.264450 (MainThread): Parsing macros/materializations/helpers.sql
2021-02-15 02:13:37.279448 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-02-15 02:13:37.284290 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-02-15 02:13:37.314360 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-02-15 02:13:37.367028 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-02-15 02:13:37.400886 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-02-15 02:13:37.406000 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-02-15 02:13:37.417523 (MainThread): Parsing macros/materializations/common/merge.sql
2021-02-15 02:13:37.442020 (MainThread): Parsing macros/materializations/table/table.sql
2021-02-15 02:13:37.454526 (MainThread): Parsing macros/materializations/view/view.sql
2021-02-15 02:13:37.469368 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-02-15 02:13:37.479225 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-02-15 02:13:37.483227 (MainThread): Parsing macros/etc/query.sql
2021-02-15 02:13:37.486511 (MainThread): Parsing macros/etc/is_incremental.sql
2021-02-15 02:13:37.491087 (MainThread): Parsing macros/etc/datetime.sql
2021-02-15 02:13:37.507136 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-02-15 02:13:37.511921 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-02-15 02:13:37.516879 (MainThread): Parsing macros/adapters/common.sql
2021-02-15 02:13:37.585071 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-02-15 02:13:37.589898 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-02-15 02:13:37.594036 (MainThread): Parsing macros/schema_tests/unique.sql
2021-02-15 02:13:37.599394 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-02-15 02:13:37.613467 (MainThread): Partial parsing not enabled
2021-02-15 02:13:37.684217 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.my_first_dbt_model".
2021-02-15 02:13:37.718148 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.my_second_dbt_model".
2021-02-15 02:13:37.737824 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_median_and_mean_US".
2021-02-15 02:13:38.137744 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1df2066e-dede-4a06-babc-e252963302a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d7b340>]}
2021-02-15 02:13:38.234816 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-02-15 02:13:38.236117 (MainThread): 
2021-02-15 02:13:38.236702 (MainThread): Acquiring new bigquery connection "master".
2021-02-15 02:13:38.243602 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_dbt-income".
2021-02-15 02:13:38.244024 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-02-15 02:13:38.630160 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_dbt-income_dbt_shafali".
2021-02-15 02:13:38.630487 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-02-15 02:13:38.635643 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-02-15 02:13:38.910419 (MainThread): 21:13:38 | Concurrency: 1 threads (target='dev')
2021-02-15 02:13:38.910782 (MainThread): 21:13:38 | 
2021-02-15 02:13:38.915944 (Thread-1): Began running node model.dbt_income_project.my_first_dbt_model
2021-02-15 02:13:38.918242 (Thread-1): 21:13:38 | 1 of 3 START table model dbt_shafali.my_first_dbt_model.............. [RUN]
2021-02-15 02:13:38.918756 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.my_first_dbt_model".
2021-02-15 02:13:38.918941 (Thread-1): Compiling model.dbt_income_project.my_first_dbt_model
2021-02-15 02:13:38.943671 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51179), raddr=('172.217.6.202', 443)>
2021-02-15 02:13:38.944330 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51181), raddr=('172.217.11.42', 443)>
2021-02-15 02:13:38.944810 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51186), raddr=('172.217.11.42', 443)>
2021-02-15 02:13:38.945469 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51183), raddr=('172.217.6.202', 443)>
2021-02-15 02:13:38.953397 (Thread-1): Writing injected SQL for node "model.dbt_income_project.my_first_dbt_model"
2021-02-15 02:13:38.954088 (Thread-1): finished collecting timing info
2021-02-15 02:13:38.988693 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:13:38.994467 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-02-15 02:13:39.346712 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.my_first_dbt_model"
2021-02-15 02:13:39.351395 (Thread-1): On model.dbt_income_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.my_first_dbt_model"} */


  create or replace table `dbt-income`.`dbt_shafali`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-02-15 02:13:40.827999 (Thread-1): finished collecting timing info
2021-02-15 02:13:40.828864 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1df2066e-dede-4a06-babc-e252963302a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c664c0>]}
2021-02-15 02:13:40.830739 (Thread-1): 21:13:40 | 1 of 3 OK created table model dbt_shafali.my_first_dbt_model......... [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 1.91s]
2021-02-15 02:13:40.831091 (Thread-1): Finished running node model.dbt_income_project.my_first_dbt_model
2021-02-15 02:13:40.831335 (Thread-1): Began running node model.dbt_income_project.acs_median_and_mean_US
2021-02-15 02:13:40.832820 (Thread-1): 21:13:40 | 2 of 3 START view model dbt_shafali.acs_median_and_mean_US........... [RUN]
2021-02-15 02:13:40.833588 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.acs_median_and_mean_US".
2021-02-15 02:13:40.833823 (Thread-1): Compiling model.dbt_income_project.acs_median_and_mean_US
2021-02-15 02:13:40.842750 (Thread-1): Writing injected SQL for node "model.dbt_income_project.acs_median_and_mean_US"
2021-02-15 02:13:40.843552 (Thread-1): finished collecting timing info
2021-02-15 02:13:40.881134 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.acs_median_and_mean_US"
2021-02-15 02:13:40.882307 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:13:40.891976 (Thread-1): On model.dbt_income_project.acs_median_and_mean_US: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.acs_median_and_mean_US"} */


  create or replace view `dbt-income`.`dbt_shafali`.`acs_median_and_mean_US`
  OPTIONS()
  as # geo_id, income_2018
WITH acs_2018 AS (
    SELECT
        geo_id,
        median_income AS income_2018,
    FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
  ),
#median_income_us
median_income_in_us_2018 AS(
    SELECT
    region, MAX(median) as median_income_in_US_2018
    FROM(
        SELECT "US" AS region,
        PERCENTILE_CONT( median_income, 0.5) 
            OVER ()AS median
        FROM bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr
    )
    AS tmp
    GROUP BY region
),
#mean_income_us
mean_income_in_us_2018 AS(
    SELECT 
     "US" AS region,AVG(median_income) AS mean_income_in_us_2018
     FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
),
acs_2018_with_statecode AS (
    SELECT
        geo_id,
        income_2018,
        geo.state_code
    FROM
        acs_2018 a18
    JOIN
        `bigquery-public-data.geo_us_boundaries.zip_codes` geo
    ON
        a18.geo_id = geo.zip_code 
    WHERE geo.state_code = 'NY' OR geo.state_code = 'CA' OR geo.state_code = 'TX' OR geo.state_code = 'FL'
),
#state median income
median_income_state_2018 AS(
    SELECT
    state_code, MAX(median) as median_income_2018
    FROM(
        SELECT state_code,
        PERCENTILE_CONT( income_2018, 0.5) 
            OVER (PARTITION BY state_code)AS median
        FROM acs_2018_with_statecode
    )
    AS tmp
    GROUP BY state_code
),
#state mean income
mean_income_state_2018 AS(
    SELECT
    state_code,
     AVG(income_2018) AS mean_income_in_2018,
    FROM
    acs_2018_with_statecode
    GROUP BY
    state_code
),
# states median + mean 
mean_median_income_state_2018 AS(
    SELECT mean_income_state_2018.state_code, mean_income_in_2018, median_income_state_2018.median_income_2018 FROM mean_income_state_2018 
    INNER JOIN  median_income_state_2018 
    ON mean_income_state_2018.state_code = median_income_state_2018.state_code
),
# US median + mean 
mean_median_income_us_2018 AS(
    SELECT median_income_in_us_2018.region,mean_income_in_us_2018.mean_income_in_US_2018, median_income_in_us_2018.median_income_in_US_2018 FROM median_income_in_us_2018 
    INNER JOIN  mean_income_in_us_2018  
    ON mean_income_in_us_2018.region = median_income_in_us_2018.region
),
state_us_mean_median_income_2018 AS(
    SELECT region, mean_income_in_US_2018, median_income_in_US_2018 
    FROM mean_median_income_us_2018
    UNION ALL
    SELECT state_code, mean_income_in_2018, median_income_2018
    FROM 
    mean_median_income_state_2018
)
SELECT * FROM state_us_mean_median_income_2018;


2021-02-15 02:13:41.932160 (Thread-1): finished collecting timing info
2021-02-15 02:13:41.933603 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1df2066e-dede-4a06-babc-e252963302a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e75850>]}
2021-02-15 02:13:41.935569 (Thread-1): 21:13:41 | 2 of 3 OK created view model dbt_shafali.acs_median_and_mean_US...... [OK in 1.10s]
2021-02-15 02:13:41.936039 (Thread-1): Finished running node model.dbt_income_project.acs_median_and_mean_US
2021-02-15 02:13:41.936451 (Thread-1): Began running node model.dbt_income_project.my_second_dbt_model
2021-02-15 02:13:41.938354 (Thread-1): 21:13:41 | 3 of 3 START view model dbt_shafali.my_second_dbt_model.............. [RUN]
2021-02-15 02:13:41.939141 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.my_second_dbt_model".
2021-02-15 02:13:41.939546 (Thread-1): Compiling model.dbt_income_project.my_second_dbt_model
2021-02-15 02:13:41.954063 (Thread-1): Writing injected SQL for node "model.dbt_income_project.my_second_dbt_model"
2021-02-15 02:13:41.955107 (Thread-1): finished collecting timing info
2021-02-15 02:13:41.964239 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.my_second_dbt_model"
2021-02-15 02:13:41.965428 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:13:41.975727 (Thread-1): On model.dbt_income_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.my_second_dbt_model"} */


  create or replace view `dbt-income`.`dbt_shafali`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `dbt-income`.`dbt_shafali`.`my_first_dbt_model`
where id = 1;


2021-02-15 02:13:42.875700 (Thread-1): finished collecting timing info
2021-02-15 02:13:42.876986 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1df2066e-dede-4a06-babc-e252963302a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d8a580>]}
2021-02-15 02:13:42.878405 (Thread-1): 21:13:42 | 3 of 3 OK created view model dbt_shafali.my_second_dbt_model......... [OK in 0.94s]
2021-02-15 02:13:42.878615 (Thread-1): Finished running node model.dbt_income_project.my_second_dbt_model
2021-02-15 02:13:42.880233 (MainThread): Acquiring new bigquery connection "master".
2021-02-15 02:13:42.880708 (MainThread): 21:13:42 | 
2021-02-15 02:13:42.880908 (MainThread): 21:13:42 | Finished running 1 table model, 2 view models in 4.64s.
2021-02-15 02:13:42.881216 (MainThread): Connection 'master' was properly closed.
2021-02-15 02:13:42.881399 (MainThread): Connection 'model.dbt_income_project.my_second_dbt_model' was properly closed.
2021-02-15 02:13:42.934703 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51188), raddr=('172.217.11.42', 443)>
2021-02-15 02:13:42.935383 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51187), raddr=('172.217.6.202', 443)>
2021-02-15 02:13:42.935859 (MainThread): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51194), raddr=('172.217.6.202', 443)>
2021-02-15 02:13:42.936262 (MainThread): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51195), raddr=('172.217.11.42', 443)>
2021-02-15 02:13:42.936702 (MainThread): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51197), raddr=('172.217.11.42', 443)>
2021-02-15 02:13:42.937119 (MainThread): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51196), raddr=('172.217.6.202', 443)>
2021-02-15 02:13:42.945923 (MainThread): 
2021-02-15 02:13:42.946291 (MainThread): Completed successfully
2021-02-15 02:13:42.946633 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2021-02-15 02:13:42.947040 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d8c220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ea9e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e39a00>]}
2021-02-15 02:13:42.947332 (MainThread): Flushing usage events
2021-02-15 02:15:46.307549 (MainThread): Running with dbt=0.19.0
2021-02-15 02:15:47.535168 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/shafaligupta/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-02-15 02:15:47.537483 (MainThread): Tracking: tracking
2021-02-15 02:15:47.554514 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111bcc880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112bd6d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112bd6c40>]}
2021-02-15 02:15:47.608352 (MainThread): Partial parsing not enabled
2021-02-15 02:15:47.611541 (MainThread): Parsing macros/etc.sql
2021-02-15 02:15:47.617625 (MainThread): Parsing macros/catalog.sql
2021-02-15 02:15:47.636369 (MainThread): Parsing macros/adapters.sql
2021-02-15 02:15:47.675090 (MainThread): Parsing macros/materializations/seed.sql
2021-02-15 02:15:47.683673 (MainThread): Parsing macros/materializations/view.sql
2021-02-15 02:15:47.690180 (MainThread): Parsing macros/materializations/table.sql
2021-02-15 02:15:47.708559 (MainThread): Parsing macros/materializations/copy.sql
2021-02-15 02:15:47.718980 (MainThread): Parsing macros/materializations/incremental.sql
2021-02-15 02:15:47.740738 (MainThread): Parsing macros/materializations/snapshot.sql
2021-02-15 02:15:47.747696 (MainThread): Parsing macros/core.sql
2021-02-15 02:15:47.755851 (MainThread): Parsing macros/materializations/helpers.sql
2021-02-15 02:15:47.771825 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-02-15 02:15:47.776180 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-02-15 02:15:47.806706 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-02-15 02:15:47.857821 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-02-15 02:15:47.892404 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-02-15 02:15:47.896978 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-02-15 02:15:47.908395 (MainThread): Parsing macros/materializations/common/merge.sql
2021-02-15 02:15:47.933944 (MainThread): Parsing macros/materializations/table/table.sql
2021-02-15 02:15:47.946633 (MainThread): Parsing macros/materializations/view/view.sql
2021-02-15 02:15:47.958131 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-02-15 02:15:47.967364 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-02-15 02:15:47.970882 (MainThread): Parsing macros/etc/query.sql
2021-02-15 02:15:47.974802 (MainThread): Parsing macros/etc/is_incremental.sql
2021-02-15 02:15:47.979394 (MainThread): Parsing macros/etc/datetime.sql
2021-02-15 02:15:47.995125 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-02-15 02:15:48.001007 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-02-15 02:15:48.006428 (MainThread): Parsing macros/adapters/common.sql
2021-02-15 02:15:48.074800 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-02-15 02:15:48.079632 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-02-15 02:15:48.084015 (MainThread): Parsing macros/schema_tests/unique.sql
2021-02-15 02:15:48.088723 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-02-15 02:15:48.101427 (MainThread): Partial parsing not enabled
2021-02-15 02:15:48.168417 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.my_first_dbt_model".
2021-02-15 02:15:48.201158 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.my_second_dbt_model".
2021-02-15 02:15:48.220138 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_median_and_mean_US_and_states_2018".
2021-02-15 02:15:48.593803 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e893c882-f094-4824-83c5-65d3fe9da6a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ecbd00>]}
2021-02-15 02:15:48.652608 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-02-15 02:15:48.654105 (MainThread): 
2021-02-15 02:15:48.654723 (MainThread): Acquiring new bigquery connection "master".
2021-02-15 02:15:48.660375 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_dbt-income".
2021-02-15 02:15:48.660739 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-02-15 02:15:48.979767 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_dbt-income_dbt_shafali".
2021-02-15 02:15:48.980106 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-02-15 02:15:48.985170 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-02-15 02:15:49.391885 (MainThread): 21:15:49 | Concurrency: 1 threads (target='dev')
2021-02-15 02:15:49.392298 (MainThread): 21:15:49 | 
2021-02-15 02:15:49.396600 (Thread-1): Began running node model.dbt_income_project.my_first_dbt_model
2021-02-15 02:15:49.398653 (Thread-1): 21:15:49 | 1 of 3 START table model dbt_shafali.my_first_dbt_model.............. [RUN]
2021-02-15 02:15:49.399173 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.my_first_dbt_model".
2021-02-15 02:15:49.399356 (Thread-1): Compiling model.dbt_income_project.my_first_dbt_model
2021-02-15 02:15:49.417441 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51274), raddr=('172.217.6.202', 443)>
2021-02-15 02:15:49.418048 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51275), raddr=('172.217.11.42', 443)>
2021-02-15 02:15:49.418469 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51277), raddr=('172.217.11.42', 443)>
2021-02-15 02:15:49.418872 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51276), raddr=('172.217.6.202', 443)>
2021-02-15 02:15:49.428349 (Thread-1): Writing injected SQL for node "model.dbt_income_project.my_first_dbt_model"
2021-02-15 02:15:49.429265 (Thread-1): finished collecting timing info
2021-02-15 02:15:49.465284 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:15:49.470421 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-02-15 02:15:49.790160 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.my_first_dbt_model"
2021-02-15 02:15:49.791376 (Thread-1): On model.dbt_income_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.my_first_dbt_model"} */


  create or replace table `dbt-income`.`dbt_shafali`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-02-15 02:15:51.720367 (Thread-1): finished collecting timing info
2021-02-15 02:15:51.722266 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e893c882-f094-4824-83c5-65d3fe9da6a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ed4520>]}
2021-02-15 02:15:51.724112 (Thread-1): 21:15:51 | 1 of 3 OK created table model dbt_shafali.my_first_dbt_model......... [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 2.32s]
2021-02-15 02:15:51.724357 (Thread-1): Finished running node model.dbt_income_project.my_first_dbt_model
2021-02-15 02:15:51.724636 (Thread-1): Began running node model.dbt_income_project.acs_median_and_mean_US_and_states_2018
2021-02-15 02:15:51.726141 (Thread-1): 21:15:51 | 2 of 3 START view model dbt_shafali.acs_median_and_mean_US_and_states_2018 [RUN]
2021-02-15 02:15:51.726792 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.acs_median_and_mean_US_and_states_2018".
2021-02-15 02:15:51.726984 (Thread-1): Compiling model.dbt_income_project.acs_median_and_mean_US_and_states_2018
2021-02-15 02:15:51.734496 (Thread-1): Writing injected SQL for node "model.dbt_income_project.acs_median_and_mean_US_and_states_2018"
2021-02-15 02:15:51.735130 (Thread-1): finished collecting timing info
2021-02-15 02:15:51.766489 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.acs_median_and_mean_US_and_states_2018"
2021-02-15 02:15:51.767182 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:15:51.772500 (Thread-1): On model.dbt_income_project.acs_median_and_mean_US_and_states_2018: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.acs_median_and_mean_US_and_states_2018"} */


  create or replace view `dbt-income`.`dbt_shafali`.`acs_median_and_mean_US_and_states_2018`
  OPTIONS()
  as # geo_id, income_2018
WITH acs_2018 AS (
    SELECT
        geo_id,
        median_income AS income_2018,
    FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
  ),
#median_income_us
median_income_in_us_2018 AS(
    SELECT
    region, MAX(median) as median_income_in_US_2018
    FROM(
        SELECT "US" AS region,
        PERCENTILE_CONT( median_income, 0.5) 
            OVER ()AS median
        FROM bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr
    )
    AS tmp
    GROUP BY region
),
#mean_income_us
mean_income_in_us_2018 AS(
    SELECT 
     "US" AS region,AVG(median_income) AS mean_income_in_us_2018
     FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
),
acs_2018_with_statecode AS (
    SELECT
        geo_id,
        income_2018,
        geo.state_code
    FROM
        acs_2018 a18
    JOIN
        `bigquery-public-data.geo_us_boundaries.zip_codes` geo
    ON
        a18.geo_id = geo.zip_code 
    WHERE geo.state_code = 'NY' OR geo.state_code = 'CA' OR geo.state_code = 'TX' OR geo.state_code = 'FL'
),
#state median income
median_income_state_2018 AS(
    SELECT
    state_code, MAX(median) as median_income_2018
    FROM(
        SELECT state_code,
        PERCENTILE_CONT( income_2018, 0.5) 
            OVER (PARTITION BY state_code)AS median
        FROM acs_2018_with_statecode
    )
    AS tmp
    GROUP BY state_code
),
#state mean income
mean_income_state_2018 AS(
    SELECT
    state_code,
     AVG(income_2018) AS mean_income_in_2018,
    FROM
    acs_2018_with_statecode
    GROUP BY
    state_code
),
# states median + mean 
mean_median_income_state_2018 AS(
    SELECT mean_income_state_2018.state_code, mean_income_in_2018, median_income_state_2018.median_income_2018 FROM mean_income_state_2018 
    INNER JOIN  median_income_state_2018 
    ON mean_income_state_2018.state_code = median_income_state_2018.state_code
),
# US median + mean 
mean_median_income_us_2018 AS(
    SELECT median_income_in_us_2018.region,mean_income_in_us_2018.mean_income_in_US_2018, median_income_in_us_2018.median_income_in_US_2018 FROM median_income_in_us_2018 
    INNER JOIN  mean_income_in_us_2018  
    ON mean_income_in_us_2018.region = median_income_in_us_2018.region
),
state_us_mean_median_income_2018 AS(
    SELECT region, mean_income_in_US_2018, median_income_in_US_2018 
    FROM mean_median_income_us_2018
    UNION ALL
    SELECT state_code, mean_income_in_2018, median_income_2018
    FROM 
    mean_median_income_state_2018
)
SELECT * FROM state_us_mean_median_income_2018;


2021-02-15 02:15:52.806335 (Thread-1): finished collecting timing info
2021-02-15 02:15:52.807493 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e893c882-f094-4824-83c5-65d3fe9da6a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115035310>]}
2021-02-15 02:15:52.808861 (Thread-1): 21:15:52 | 2 of 3 OK created view model dbt_shafali.acs_median_and_mean_US_and_states_2018 [OK in 1.08s]
2021-02-15 02:15:52.809062 (Thread-1): Finished running node model.dbt_income_project.acs_median_and_mean_US_and_states_2018
2021-02-15 02:15:52.809274 (Thread-1): Began running node model.dbt_income_project.my_second_dbt_model
2021-02-15 02:15:52.810783 (Thread-1): 21:15:52 | 3 of 3 START view model dbt_shafali.my_second_dbt_model.............. [RUN]
2021-02-15 02:15:52.811271 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.my_second_dbt_model".
2021-02-15 02:15:52.811445 (Thread-1): Compiling model.dbt_income_project.my_second_dbt_model
2021-02-15 02:15:52.823308 (Thread-1): Writing injected SQL for node "model.dbt_income_project.my_second_dbt_model"
2021-02-15 02:15:52.823945 (Thread-1): finished collecting timing info
2021-02-15 02:15:52.830226 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.my_second_dbt_model"
2021-02-15 02:15:52.831219 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:15:52.836689 (Thread-1): On model.dbt_income_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.my_second_dbt_model"} */


  create or replace view `dbt-income`.`dbt_shafali`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `dbt-income`.`dbt_shafali`.`my_first_dbt_model`
where id = 1;


2021-02-15 02:15:53.886125 (Thread-1): finished collecting timing info
2021-02-15 02:15:53.887494 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e893c882-f094-4824-83c5-65d3fe9da6a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1150b6be0>]}
2021-02-15 02:15:53.889177 (Thread-1): 21:15:53 | 3 of 3 OK created view model dbt_shafali.my_second_dbt_model......... [OK in 1.08s]
2021-02-15 02:15:53.889394 (Thread-1): Finished running node model.dbt_income_project.my_second_dbt_model
2021-02-15 02:15:53.890913 (MainThread): Acquiring new bigquery connection "master".
2021-02-15 02:15:53.891334 (MainThread): 21:15:53 | 
2021-02-15 02:15:53.891506 (MainThread): 21:15:53 | Finished running 1 table model, 2 view models in 5.24s.
2021-02-15 02:15:53.891663 (MainThread): Connection 'master' was properly closed.
2021-02-15 02:15:53.891798 (MainThread): Connection 'model.dbt_income_project.my_second_dbt_model' was properly closed.
2021-02-15 02:15:53.945090 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51279), raddr=('172.217.11.42', 443)>
2021-02-15 02:15:53.945755 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51278), raddr=('172.217.6.202', 443)>
2021-02-15 02:15:53.946376 (MainThread): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51283), raddr=('172.217.6.202', 443)>
2021-02-15 02:15:53.946928 (MainThread): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51284), raddr=('172.217.11.42', 443)>
2021-02-15 02:15:53.947539 (MainThread): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51288), raddr=('172.217.11.42', 443)>
2021-02-15 02:15:53.948096 (MainThread): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51287), raddr=('172.217.6.202', 443)>
2021-02-15 02:15:53.957493 (MainThread): 
2021-02-15 02:15:53.957804 (MainThread): Completed successfully
2021-02-15 02:15:53.958123 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2021-02-15 02:15:53.958599 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112efe3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e305b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ed4f10>]}
2021-02-15 02:15:53.958931 (MainThread): Flushing usage events
2021-02-15 02:22:37.670584 (MainThread): Running with dbt=0.19.0
2021-02-15 02:22:38.981183 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/shafaligupta/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-02-15 02:22:38.984000 (MainThread): Tracking: tracking
2021-02-15 02:22:38.996820 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107cd8a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ce8490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ce8370>]}
2021-02-15 02:22:39.058333 (MainThread): Partial parsing not enabled
2021-02-15 02:22:39.061404 (MainThread): Parsing macros/etc.sql
2021-02-15 02:22:39.066941 (MainThread): Parsing macros/catalog.sql
2021-02-15 02:22:39.078987 (MainThread): Parsing macros/adapters.sql
2021-02-15 02:22:39.113554 (MainThread): Parsing macros/materializations/seed.sql
2021-02-15 02:22:39.120918 (MainThread): Parsing macros/materializations/view.sql
2021-02-15 02:22:39.127574 (MainThread): Parsing macros/materializations/table.sql
2021-02-15 02:22:39.146264 (MainThread): Parsing macros/materializations/copy.sql
2021-02-15 02:22:39.155276 (MainThread): Parsing macros/materializations/incremental.sql
2021-02-15 02:22:39.177206 (MainThread): Parsing macros/materializations/snapshot.sql
2021-02-15 02:22:39.186634 (MainThread): Parsing macros/core.sql
2021-02-15 02:22:39.198212 (MainThread): Parsing macros/materializations/helpers.sql
2021-02-15 02:22:39.214676 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-02-15 02:22:39.219621 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-02-15 02:22:39.249639 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-02-15 02:22:39.308745 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-02-15 02:22:39.344639 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-02-15 02:22:39.350113 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-02-15 02:22:39.362203 (MainThread): Parsing macros/materializations/common/merge.sql
2021-02-15 02:22:39.402350 (MainThread): Parsing macros/materializations/table/table.sql
2021-02-15 02:22:39.417526 (MainThread): Parsing macros/materializations/view/view.sql
2021-02-15 02:22:39.432006 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-02-15 02:22:39.443381 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-02-15 02:22:39.447881 (MainThread): Parsing macros/etc/query.sql
2021-02-15 02:22:39.450707 (MainThread): Parsing macros/etc/is_incremental.sql
2021-02-15 02:22:39.455629 (MainThread): Parsing macros/etc/datetime.sql
2021-02-15 02:22:39.485816 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-02-15 02:22:39.495762 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-02-15 02:22:39.501602 (MainThread): Parsing macros/adapters/common.sql
2021-02-15 02:22:39.613287 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-02-15 02:22:39.623196 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-02-15 02:22:39.628172 (MainThread): Parsing macros/schema_tests/unique.sql
2021-02-15 02:22:39.633454 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-02-15 02:22:39.663461 (MainThread): Partial parsing not enabled
2021-02-15 02:22:39.741852 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.my_first_dbt_model".
2021-02-15 02:22:39.775801 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.my_second_dbt_model".
2021-02-15 02:22:39.793787 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_US_2018".
2021-02-15 02:22:39.811891 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_median_and_mean_US_and_states_2018".
2021-02-15 02:22:40.199921 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b1c1feab-a70c-4ca9-b60a-30db1dbedf04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f55790>]}
2021-02-15 02:22:40.300313 (MainThread): Found 4 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-02-15 02:22:40.301658 (MainThread): 
2021-02-15 02:22:40.302190 (MainThread): Acquiring new bigquery connection "master".
2021-02-15 02:22:40.309685 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_dbt-income".
2021-02-15 02:22:40.310019 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-02-15 02:22:40.995396 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_dbt-income_dbt_shafali".
2021-02-15 02:22:40.995989 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-02-15 02:22:41.001260 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-02-15 02:22:41.409012 (MainThread): 21:22:41 | Concurrency: 1 threads (target='dev')
2021-02-15 02:22:41.409309 (MainThread): 21:22:41 | 
2021-02-15 02:22:41.412860 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51432), raddr=('172.217.10.106', 443)>
2021-02-15 02:22:41.413543 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51433), raddr=('142.250.64.74', 443)>
2021-02-15 02:22:41.416308 (Thread-1): Began running node model.dbt_income_project.my_first_dbt_model
2021-02-15 02:22:41.418890 (Thread-1): 21:22:41 | 1 of 4 START table model dbt_shafali.my_first_dbt_model.............. [RUN]
2021-02-15 02:22:41.419641 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.my_first_dbt_model".
2021-02-15 02:22:41.419943 (Thread-1): Compiling model.dbt_income_project.my_first_dbt_model
2021-02-15 02:22:41.456483 (Thread-1): Writing injected SQL for node "model.dbt_income_project.my_first_dbt_model"
2021-02-15 02:22:41.457259 (Thread-1): finished collecting timing info
2021-02-15 02:22:41.499089 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:22:41.508840 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-02-15 02:22:41.977099 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.my_first_dbt_model"
2021-02-15 02:22:41.978233 (Thread-1): On model.dbt_income_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.my_first_dbt_model"} */


  create or replace table `dbt-income`.`dbt_shafali`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-02-15 02:22:43.450633 (Thread-1): finished collecting timing info
2021-02-15 02:22:43.451586 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1c1feab-a70c-4ca9-b60a-30db1dbedf04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080f0670>]}
2021-02-15 02:22:43.453177 (Thread-1): 21:22:43 | 1 of 4 OK created table model dbt_shafali.my_first_dbt_model......... [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 2.03s]
2021-02-15 02:22:43.453424 (Thread-1): Finished running node model.dbt_income_project.my_first_dbt_model
2021-02-15 02:22:43.453810 (Thread-1): Began running node model.dbt_income_project.acs_median_and_mean_US_and_states_2018
2021-02-15 02:22:43.455334 (Thread-1): 21:22:43 | 2 of 4 START view model dbt_shafali.acs_median_and_mean_US_and_states_2018 [RUN]
2021-02-15 02:22:43.456025 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.acs_median_and_mean_US_and_states_2018".
2021-02-15 02:22:43.456216 (Thread-1): Compiling model.dbt_income_project.acs_median_and_mean_US_and_states_2018
2021-02-15 02:22:43.463841 (Thread-1): Writing injected SQL for node "model.dbt_income_project.acs_median_and_mean_US_and_states_2018"
2021-02-15 02:22:43.464602 (Thread-1): finished collecting timing info
2021-02-15 02:22:43.503178 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.acs_median_and_mean_US_and_states_2018"
2021-02-15 02:22:43.504299 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:22:43.509511 (Thread-1): On model.dbt_income_project.acs_median_and_mean_US_and_states_2018: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.acs_median_and_mean_US_and_states_2018"} */


  create or replace view `dbt-income`.`dbt_shafali`.`acs_median_and_mean_US_and_states_2018`
  OPTIONS()
  as # geo_id, income_2018
WITH acs_2018 AS (
    SELECT
        geo_id,
        median_income AS income_2018,
    FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
  ),
#median_income_us
median_income_in_us_2018 AS(
    SELECT
    region, MAX(median) as median_income_in_US_2018
    FROM(
        SELECT "US" AS region,
        PERCENTILE_CONT( median_income, 0.5) 
            OVER ()AS median
        FROM bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr
    )
    AS tmp
    GROUP BY region
),
#mean_income_us
mean_income_in_us_2018 AS(
    SELECT 
     "US" AS region,AVG(median_income) AS mean_income_in_us_2018
     FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
),
acs_2018_with_statecode AS (
    SELECT
        geo_id,
        income_2018,
        geo.state_code
    FROM
        acs_2018 a18
    JOIN
        `bigquery-public-data.geo_us_boundaries.zip_codes` geo
    ON
        a18.geo_id = geo.zip_code 
    WHERE geo.state_code = 'NY' OR geo.state_code = 'CA' OR geo.state_code = 'TX' OR geo.state_code = 'FL'
),
#state median income
median_income_state_2018 AS(
    SELECT
    state_code, MAX(median) as median_income_2018
    FROM(
        SELECT state_code,
        PERCENTILE_CONT( income_2018, 0.5) 
            OVER (PARTITION BY state_code)AS median
        FROM acs_2018_with_statecode
    )
    AS tmp
    GROUP BY state_code
),
#state mean income
mean_income_state_2018 AS(
    SELECT
    state_code,
     AVG(income_2018) AS mean_income_in_2018,
    FROM
    acs_2018_with_statecode
    GROUP BY
    state_code
),
# states median + mean 
mean_median_income_state_2018 AS(
    SELECT mean_income_state_2018.state_code, mean_income_in_2018, median_income_state_2018.median_income_2018 FROM mean_income_state_2018 
    INNER JOIN  median_income_state_2018 
    ON mean_income_state_2018.state_code = median_income_state_2018.state_code
),
# US median + mean 
mean_median_income_us_2018 AS(
    SELECT median_income_in_us_2018.region,mean_income_in_us_2018.mean_income_in_US_2018, median_income_in_us_2018.median_income_in_US_2018 FROM median_income_in_us_2018 
    INNER JOIN  mean_income_in_us_2018  
    ON mean_income_in_us_2018.region = median_income_in_us_2018.region
),
state_us_mean_median_income_2018 AS(
    SELECT region, mean_income_in_US_2018, median_income_in_US_2018 
    FROM mean_median_income_us_2018
    UNION ALL
    SELECT state_code, mean_income_in_2018, median_income_2018
    FROM 
    mean_median_income_state_2018
)
SELECT * FROM state_us_mean_median_income_2018;


2021-02-15 02:22:44.612308 (Thread-1): finished collecting timing info
2021-02-15 02:22:44.613991 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1c1feab-a70c-4ca9-b60a-30db1dbedf04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080f5b50>]}
2021-02-15 02:22:44.616877 (Thread-1): 21:22:44 | 2 of 4 OK created view model dbt_shafali.acs_median_and_mean_US_and_states_2018 [OK in 1.16s]
2021-02-15 02:22:44.617357 (Thread-1): Finished running node model.dbt_income_project.acs_median_and_mean_US_and_states_2018
2021-02-15 02:22:44.618205 (Thread-1): Began running node model.dbt_income_project.acs_percentile_US_2018
2021-02-15 02:22:44.621257 (Thread-1): 21:22:44 | 3 of 4 START view model dbt_shafali.acs_percentile_US_2018........... [RUN]
2021-02-15 02:22:44.622045 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_US_2018".
2021-02-15 02:22:44.622352 (Thread-1): Compiling model.dbt_income_project.acs_percentile_US_2018
2021-02-15 02:22:44.638325 (Thread-1): Writing injected SQL for node "model.dbt_income_project.acs_percentile_US_2018"
2021-02-15 02:22:44.638963 (Thread-1): finished collecting timing info
2021-02-15 02:22:44.646852 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.acs_percentile_US_2018"
2021-02-15 02:22:44.647588 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:22:44.657446 (Thread-1): On model.dbt_income_project.acs_percentile_US_2018: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.acs_percentile_US_2018"} */


  create or replace view `dbt-income`.`dbt_shafali`.`acs_percentile_US_2018`
  OPTIONS()
  as SELECT  
  percentiles[offset(10)] as p10,
  percentiles[offset(25)] as p25,
  percentiles[offset(50)] as p50,
  percentiles[offset(75)] as p75,
  percentiles[offset(90)] as p90,
from (
  select approx_quantiles(median_income, 100) percentiles
  from  `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
);


2021-02-15 02:22:45.632318 (Thread-1): finished collecting timing info
2021-02-15 02:22:45.633416 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1c1feab-a70c-4ca9-b60a-30db1dbedf04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081590a0>]}
2021-02-15 02:22:45.635138 (Thread-1): 21:22:45 | 3 of 4 OK created view model dbt_shafali.acs_percentile_US_2018...... [OK in 1.01s]
2021-02-15 02:22:45.635400 (Thread-1): Finished running node model.dbt_income_project.acs_percentile_US_2018
2021-02-15 02:22:45.635671 (Thread-1): Began running node model.dbt_income_project.my_second_dbt_model
2021-02-15 02:22:45.637344 (Thread-1): 21:22:45 | 4 of 4 START view model dbt_shafali.my_second_dbt_model.............. [RUN]
2021-02-15 02:22:45.641337 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.my_second_dbt_model".
2021-02-15 02:22:45.643338 (Thread-1): Compiling model.dbt_income_project.my_second_dbt_model
2021-02-15 02:22:45.653084 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51439), raddr=('142.250.64.74', 443)>
2021-02-15 02:22:45.653644 (Thread-1): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51438), raddr=('172.217.10.106', 443)>
2021-02-15 02:22:45.654070 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51442), raddr=('172.217.10.106', 443)>
2021-02-15 02:22:45.654455 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51443), raddr=('142.250.64.74', 443)>
2021-02-15 02:22:45.654862 (Thread-1): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51446), raddr=('142.250.64.74', 443)>
2021-02-15 02:22:45.655347 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51445), raddr=('172.217.10.106', 443)>
2021-02-15 02:22:45.659048 (Thread-1): Writing injected SQL for node "model.dbt_income_project.my_second_dbt_model"
2021-02-15 02:22:45.659709 (Thread-1): finished collecting timing info
2021-02-15 02:22:45.667579 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.my_second_dbt_model"
2021-02-15 02:22:45.669917 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:22:45.677585 (Thread-1): On model.dbt_income_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.my_second_dbt_model"} */


  create or replace view `dbt-income`.`dbt_shafali`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `dbt-income`.`dbt_shafali`.`my_first_dbt_model`
where id = 1;


2021-02-15 02:22:46.689780 (Thread-1): finished collecting timing info
2021-02-15 02:22:46.690909 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1c1feab-a70c-4ca9-b60a-30db1dbedf04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080ce3d0>]}
2021-02-15 02:22:46.692379 (Thread-1): 21:22:46 | 4 of 4 OK created view model dbt_shafali.my_second_dbt_model......... [OK in 1.05s]
2021-02-15 02:22:46.692603 (Thread-1): Finished running node model.dbt_income_project.my_second_dbt_model
2021-02-15 02:22:46.694147 (MainThread): Acquiring new bigquery connection "master".
2021-02-15 02:22:46.694569 (MainThread): 21:22:46 | 
2021-02-15 02:22:46.694958 (MainThread): 21:22:46 | Finished running 1 table model, 3 view models in 6.39s.
2021-02-15 02:22:46.695208 (MainThread): Connection 'master' was properly closed.
2021-02-15 02:22:46.695358 (MainThread): Connection 'model.dbt_income_project.my_second_dbt_model' was properly closed.
2021-02-15 02:22:46.768139 (MainThread): 
2021-02-15 02:22:46.768439 (MainThread): Completed successfully
2021-02-15 02:22:46.768780 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-02-15 02:22:46.769212 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108180cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10814a340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d45820>]}
2021-02-15 02:22:46.769557 (MainThread): Flushing usage events
2021-02-15 02:27:20.678833 (MainThread): Running with dbt=0.19.0
2021-02-15 02:27:22.063806 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/shafaligupta/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-02-15 02:27:22.065461 (MainThread): Tracking: tracking
2021-02-15 02:27:22.078909 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112cbeeb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112cce7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112cce6d0>]}
2021-02-15 02:27:22.141148 (MainThread): Partial parsing not enabled
2021-02-15 02:27:22.144410 (MainThread): Parsing macros/etc.sql
2021-02-15 02:27:22.149708 (MainThread): Parsing macros/catalog.sql
2021-02-15 02:27:22.161325 (MainThread): Parsing macros/adapters.sql
2021-02-15 02:27:22.200409 (MainThread): Parsing macros/materializations/seed.sql
2021-02-15 02:27:22.206208 (MainThread): Parsing macros/materializations/view.sql
2021-02-15 02:27:22.213081 (MainThread): Parsing macros/materializations/table.sql
2021-02-15 02:27:22.230463 (MainThread): Parsing macros/materializations/copy.sql
2021-02-15 02:27:22.239010 (MainThread): Parsing macros/materializations/incremental.sql
2021-02-15 02:27:22.261261 (MainThread): Parsing macros/materializations/snapshot.sql
2021-02-15 02:27:22.270804 (MainThread): Parsing macros/core.sql
2021-02-15 02:27:22.279399 (MainThread): Parsing macros/materializations/helpers.sql
2021-02-15 02:27:22.294683 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-02-15 02:27:22.299596 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-02-15 02:27:22.328678 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-02-15 02:27:22.379247 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-02-15 02:27:22.414108 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-02-15 02:27:22.418608 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-02-15 02:27:22.429772 (MainThread): Parsing macros/materializations/common/merge.sql
2021-02-15 02:27:22.452365 (MainThread): Parsing macros/materializations/table/table.sql
2021-02-15 02:27:22.464480 (MainThread): Parsing macros/materializations/view/view.sql
2021-02-15 02:27:22.476544 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-02-15 02:27:22.485952 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-02-15 02:27:22.489427 (MainThread): Parsing macros/etc/query.sql
2021-02-15 02:27:22.492548 (MainThread): Parsing macros/etc/is_incremental.sql
2021-02-15 02:27:22.499171 (MainThread): Parsing macros/etc/datetime.sql
2021-02-15 02:27:22.514812 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-02-15 02:27:22.519778 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-02-15 02:27:22.525887 (MainThread): Parsing macros/adapters/common.sql
2021-02-15 02:27:22.594798 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-02-15 02:27:22.599603 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-02-15 02:27:22.604300 (MainThread): Parsing macros/schema_tests/unique.sql
2021-02-15 02:27:22.609238 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-02-15 02:27:22.622051 (MainThread): Partial parsing not enabled
2021-02-15 02:27:22.686970 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.my_first_dbt_model".
2021-02-15 02:27:22.719668 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.my_second_dbt_model".
2021-02-15 02:27:22.737868 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_US_2018".
2021-02-15 02:27:22.757276 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_FL_2018".
2021-02-15 02:27:22.776689 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_median_and_mean_US_and_states_2018".
2021-02-15 02:27:22.794942 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_TX_2018".
2021-02-15 02:27:22.812699 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_CS_2018".
2021-02-15 02:27:22.880117 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_NY_2018".
2021-02-15 02:27:23.215625 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd5111fd0-4708-451f-b17d-a875d44b5784', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112fdb4c0>]}
2021-02-15 02:27:23.296478 (MainThread): Found 8 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-02-15 02:27:23.298124 (MainThread): 
2021-02-15 02:27:23.298728 (MainThread): Acquiring new bigquery connection "master".
2021-02-15 02:27:23.313402 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_dbt-income".
2021-02-15 02:27:23.313802 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-02-15 02:27:23.784386 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_dbt-income_dbt_shafali".
2021-02-15 02:27:23.784707 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-02-15 02:27:23.789950 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-02-15 02:27:24.217425 (MainThread): 21:27:24 | Concurrency: 1 threads (target='dev')
2021-02-15 02:27:24.217923 (MainThread): 21:27:24 | 
2021-02-15 02:27:24.222810 (Thread-1): Began running node model.dbt_income_project.my_first_dbt_model
2021-02-15 02:27:24.224639 (Thread-1): 21:27:24 | 1 of 8 START table model dbt_shafali.my_first_dbt_model.............. [RUN]
2021-02-15 02:27:24.225228 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.my_first_dbt_model".
2021-02-15 02:27:24.225429 (Thread-1): Compiling model.dbt_income_project.my_first_dbt_model
2021-02-15 02:27:24.253785 (Thread-1): Writing injected SQL for node "model.dbt_income_project.my_first_dbt_model"
2021-02-15 02:27:24.254594 (Thread-1): finished collecting timing info
2021-02-15 02:27:24.290174 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:27:24.295405 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-02-15 02:27:24.608629 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.my_first_dbt_model"
2021-02-15 02:27:24.610862 (Thread-1): On model.dbt_income_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.my_first_dbt_model"} */


  create or replace table `dbt-income`.`dbt_shafali`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-02-15 02:27:26.090801 (Thread-1): finished collecting timing info
2021-02-15 02:27:26.091750 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd5111fd0-4708-451f-b17d-a875d44b5784', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d44ac0>]}
2021-02-15 02:27:26.093164 (Thread-1): 21:27:26 | 1 of 8 OK created table model dbt_shafali.my_first_dbt_model......... [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 1.87s]
2021-02-15 02:27:26.093386 (Thread-1): Finished running node model.dbt_income_project.my_first_dbt_model
2021-02-15 02:27:26.093648 (Thread-1): Began running node model.dbt_income_project.acs_median_and_mean_US_and_states_2018
2021-02-15 02:27:26.095187 (Thread-1): 21:27:26 | 2 of 8 START view model dbt_shafali.acs_median_and_mean_US_and_states_2018 [RUN]
2021-02-15 02:27:26.095832 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.acs_median_and_mean_US_and_states_2018".
2021-02-15 02:27:26.096020 (Thread-1): Compiling model.dbt_income_project.acs_median_and_mean_US_and_states_2018
2021-02-15 02:27:26.101568 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51555), raddr=('172.217.10.106', 443)>
2021-02-15 02:27:26.102125 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51556), raddr=('142.250.64.74', 443)>
2021-02-15 02:27:26.102635 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51557), raddr=('172.217.10.106', 443)>
2021-02-15 02:27:26.103070 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51559), raddr=('142.250.64.74', 443)>
2021-02-15 02:27:26.103511 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51562), raddr=('142.250.64.74', 443)>
2021-02-15 02:27:26.103900 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51561), raddr=('172.217.10.106', 443)>
2021-02-15 02:27:26.108179 (Thread-1): Writing injected SQL for node "model.dbt_income_project.acs_median_and_mean_US_and_states_2018"
2021-02-15 02:27:26.109273 (Thread-1): finished collecting timing info
2021-02-15 02:27:26.140600 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.acs_median_and_mean_US_and_states_2018"
2021-02-15 02:27:26.142320 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:27:26.147629 (Thread-1): On model.dbt_income_project.acs_median_and_mean_US_and_states_2018: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.acs_median_and_mean_US_and_states_2018"} */


  create or replace view `dbt-income`.`dbt_shafali`.`acs_median_and_mean_US_and_states_2018`
  OPTIONS()
  as # geo_id, income_2018
WITH acs_2018 AS (
    SELECT
        geo_id,
        median_income AS income_2018,
    FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
  ),
#median_income_us
median_income_in_us_2018 AS(
    SELECT
    region, MAX(median) as median_income_in_US_2018
    FROM(
        SELECT "US" AS region,
        PERCENTILE_CONT( median_income, 0.5) 
            OVER ()AS median
        FROM bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr
    )
    AS tmp
    GROUP BY region
),
#mean_income_us
mean_income_in_us_2018 AS(
    SELECT 
     "US" AS region,AVG(median_income) AS mean_income_in_us_2018
     FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
),
acs_2018_with_statecode AS (
    SELECT
        geo_id,
        income_2018,
        geo.state_code
    FROM
        acs_2018 a18
    JOIN
        `bigquery-public-data.geo_us_boundaries.zip_codes` geo
    ON
        a18.geo_id = geo.zip_code 
    WHERE geo.state_code = 'NY' OR geo.state_code = 'CA' OR geo.state_code = 'TX' OR geo.state_code = 'FL'
),
#state median income
median_income_state_2018 AS(
    SELECT
    state_code, MAX(median) as median_income_2018
    FROM(
        SELECT state_code,
        PERCENTILE_CONT( income_2018, 0.5) 
            OVER (PARTITION BY state_code)AS median
        FROM acs_2018_with_statecode
    )
    AS tmp
    GROUP BY state_code
),
#state mean income
mean_income_state_2018 AS(
    SELECT
    state_code,
     AVG(income_2018) AS mean_income_in_2018,
    FROM
    acs_2018_with_statecode
    GROUP BY
    state_code
),
# states median + mean 
mean_median_income_state_2018 AS(
    SELECT mean_income_state_2018.state_code, mean_income_in_2018, median_income_state_2018.median_income_2018 FROM mean_income_state_2018 
    INNER JOIN  median_income_state_2018 
    ON mean_income_state_2018.state_code = median_income_state_2018.state_code
),
# US median + mean 
mean_median_income_us_2018 AS(
    SELECT median_income_in_us_2018.region,mean_income_in_us_2018.mean_income_in_US_2018, median_income_in_us_2018.median_income_in_US_2018 FROM median_income_in_us_2018 
    INNER JOIN  mean_income_in_us_2018  
    ON mean_income_in_us_2018.region = median_income_in_us_2018.region
),
state_us_mean_median_income_2018 AS(
    SELECT region, mean_income_in_US_2018, median_income_in_US_2018 
    FROM mean_median_income_us_2018
    UNION ALL
    SELECT state_code, mean_income_in_2018, median_income_2018
    FROM 
    mean_median_income_state_2018
)
SELECT * FROM state_us_mean_median_income_2018;


2021-02-15 02:27:27.115636 (Thread-1): finished collecting timing info
2021-02-15 02:27:27.116667 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd5111fd0-4708-451f-b17d-a875d44b5784', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112f4eaf0>]}
2021-02-15 02:27:27.118313 (Thread-1): 21:27:27 | 2 of 8 OK created view model dbt_shafali.acs_median_and_mean_US_and_states_2018 [OK in 1.02s]
2021-02-15 02:27:27.118685 (Thread-1): Finished running node model.dbt_income_project.acs_median_and_mean_US_and_states_2018
2021-02-15 02:27:27.119143 (Thread-1): Began running node model.dbt_income_project.acs_percentile_CS_2018
2021-02-15 02:27:27.121109 (Thread-1): 21:27:27 | 3 of 8 START view model dbt_shafali.acs_percentile_CS_2018........... [RUN]
2021-02-15 02:27:27.121735 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_CS_2018".
2021-02-15 02:27:27.122064 (Thread-1): Compiling model.dbt_income_project.acs_percentile_CS_2018
2021-02-15 02:27:27.133417 (Thread-1): Writing injected SQL for node "model.dbt_income_project.acs_percentile_CS_2018"
2021-02-15 02:27:27.134057 (Thread-1): finished collecting timing info
2021-02-15 02:27:27.141897 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.acs_percentile_CS_2018"
2021-02-15 02:27:27.142687 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:27:27.150183 (Thread-1): On model.dbt_income_project.acs_percentile_CS_2018: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.acs_percentile_CS_2018"} */


  create or replace view `dbt-income`.`dbt_shafali`.`acs_percentile_CS_2018`
  OPTIONS()
  as WITH acs_2018 AS (
    SELECT
        geo_id,
        median_income AS income_2018,
    FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
  ),

median_income_in_us_2018 AS(
 
    SELECT
    region, MAX(median) as median_income_in_US_2018
    FROM(
        SELECT "US" AS region,
        PERCENTILE_CONT( median_income, 0.5) 
            OVER ()AS median
        FROM bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr
    )
    AS tmp
    GROUP BY region
    
),

mean_income_in_us_2018 AS(
    SELECT 
     "US" AS region,AVG(median_income) AS mean_income_in_us_2018
     FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
),
acs_2018_with_statecode AS (
    SELECT
        geo_id,
        income_2018,
        geo.state_code
    FROM
        acs_2018 a18
    JOIN
        `bigquery-public-data.geo_us_boundaries.zip_codes` geo
    ON
        a18.geo_id = geo.zip_code 
    WHERE geo.state_code = 'NY' OR geo.state_code = 'CA' OR geo.state_code = 'TX' OR geo.state_code = 'FL'
),

median_income_state_2018 AS(
    SELECT
    state_code, MAX(median) as median_income_2018
    FROM(
        SELECT state_code,
        PERCENTILE_CONT( income_2018, 0.5) 
            OVER (PARTITION BY state_code)AS median
        FROM acs_2018_with_statecode
    )
    AS tmp
    GROUP BY state_code
),

mean_income_state_2018 AS(
    SELECT
    state_code,
     AVG(income_2018) AS mean_income_in_2018,

    FROM
    acs_2018_with_statecode
    
    GROUP BY
    state_code
),
 
mean_median_income_state_2018 AS(

    SELECT mean_income_state_2018.state_code, mean_income_in_2018, median_income_state_2018.median_income_2018 FROM mean_income_state_2018 
    INNER JOIN  median_income_state_2018 
    ON mean_income_state_2018.state_code = median_income_state_2018.state_code
 
),


mean_median_income_us_2018 AS(
    SELECT  median_income_in_us_2018.region,mean_income_in_us_2018.mean_income_in_US_2018, median_income_in_us_2018.median_income_in_US_2018 FROM median_income_in_us_2018 
    INNER JOIN  mean_income_in_us_2018  
    ON mean_income_in_us_2018.region = median_income_in_us_2018.region
 
)


SELECT  
  percentiles[offset(10)] as p10,
  percentiles[offset(25)] as p25,
  percentiles[offset(50)] as p50,
  percentiles[offset(75)] as p75,
  percentiles[offset(90)] as p90,
FROM (
  SELECT approx_quantiles(income_2018 , 100) percentiles
    FROM (
        SELECT state_code, income_2018 
        FROM acs_2018_with_statecode
        WHERE state_code = 'CA'
    ) AS income
);


2021-02-15 02:27:28.117512 (Thread-1): finished collecting timing info
2021-02-15 02:27:28.118675 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd5111fd0-4708-451f-b17d-a875d44b5784', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112f4eaf0>]}
2021-02-15 02:27:28.121004 (Thread-1): 21:27:28 | 3 of 8 OK created view model dbt_shafali.acs_percentile_CS_2018...... [OK in 1.00s]
2021-02-15 02:27:28.121414 (Thread-1): Finished running node model.dbt_income_project.acs_percentile_CS_2018
2021-02-15 02:27:28.121838 (Thread-1): Began running node model.dbt_income_project.acs_percentile_FL_2018
2021-02-15 02:27:28.124722 (Thread-1): 21:27:28 | 4 of 8 START view model dbt_shafali.acs_percentile_FL_2018........... [RUN]
2021-02-15 02:27:28.125616 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_FL_2018".
2021-02-15 02:27:28.125990 (Thread-1): Compiling model.dbt_income_project.acs_percentile_FL_2018
2021-02-15 02:27:28.138766 (Thread-1): Writing injected SQL for node "model.dbt_income_project.acs_percentile_FL_2018"
2021-02-15 02:27:28.140040 (Thread-1): finished collecting timing info
2021-02-15 02:27:28.153624 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.acs_percentile_FL_2018"
2021-02-15 02:27:28.154720 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:27:28.172693 (Thread-1): On model.dbt_income_project.acs_percentile_FL_2018: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.acs_percentile_FL_2018"} */


  create or replace view `dbt-income`.`dbt_shafali`.`acs_percentile_FL_2018`
  OPTIONS()
  as WITH acs_2018 AS (
    SELECT
        geo_id,
        median_income AS income_2018,
    FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
  ),

median_income_in_us_2018 AS(
 
    SELECT
    region, MAX(median) as median_income_in_US_2018
    FROM(
        SELECT "US" AS region,
        PERCENTILE_CONT( median_income, 0.5) 
            OVER ()AS median
        FROM bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr
    )
    AS tmp
    GROUP BY region
    
),

mean_income_in_us_2018 AS(
    SELECT 
     "US" AS region,AVG(median_income) AS mean_income_in_us_2018
     FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
),
acs_2018_with_statecode AS (
    SELECT
        geo_id,
        income_2018,
        geo.state_code
    FROM
        acs_2018 a18
    JOIN
        `bigquery-public-data.geo_us_boundaries.zip_codes` geo
    ON
        a18.geo_id = geo.zip_code 
    WHERE geo.state_code = 'NY' OR geo.state_code = 'CA' OR geo.state_code = 'TX' OR geo.state_code = 'FL'
),

median_income_state_2018 AS(
    SELECT
    state_code, MAX(median) as median_income_2018
    FROM(
        SELECT state_code,
        PERCENTILE_CONT( income_2018, 0.5) 
            OVER (PARTITION BY state_code)AS median
        FROM acs_2018_with_statecode
    )
    AS tmp
    GROUP BY state_code
),

mean_income_state_2018 AS(
    SELECT
    state_code,
     AVG(income_2018) AS mean_income_in_2018,

    FROM
    acs_2018_with_statecode
    
    GROUP BY
    state_code
),
 
mean_median_income_state_2018 AS(

    SELECT mean_income_state_2018.state_code, mean_income_in_2018, median_income_state_2018.median_income_2018 FROM mean_income_state_2018 
    INNER JOIN  median_income_state_2018 
    ON mean_income_state_2018.state_code = median_income_state_2018.state_code
 
),


mean_median_income_us_2018 AS(
    SELECT  median_income_in_us_2018.region,mean_income_in_us_2018.mean_income_in_US_2018, median_income_in_us_2018.median_income_in_US_2018 FROM median_income_in_us_2018 
    INNER JOIN  mean_income_in_us_2018  
    ON mean_income_in_us_2018.region = median_income_in_us_2018.region
 
)


SELECT  
  percentiles[offset(10)] as p10,
  percentiles[offset(25)] as p25,
  percentiles[offset(50)] as p50,
  percentiles[offset(75)] as p75,
  percentiles[offset(90)] as p90,
FROM (
  SELECT approx_quantiles(income_2018 , 100) percentiles
    FROM (
        SELECT state_code, income_2018 
        FROM acs_2018_with_statecode
        WHERE state_code = 'FL'
    ) AS income
);


2021-02-15 02:27:29.042714 (Thread-1): finished collecting timing info
2021-02-15 02:27:29.043900 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd5111fd0-4708-451f-b17d-a875d44b5784', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1130dfac0>]}
2021-02-15 02:27:29.045502 (Thread-1): 21:27:29 | 4 of 8 OK created view model dbt_shafali.acs_percentile_FL_2018...... [OK in 0.92s]
2021-02-15 02:27:29.045705 (Thread-1): Finished running node model.dbt_income_project.acs_percentile_FL_2018
2021-02-15 02:27:29.045990 (Thread-1): Began running node model.dbt_income_project.acs_percentile_NY_2018
2021-02-15 02:27:29.047404 (Thread-1): 21:27:29 | 5 of 8 START view model dbt_shafali.acs_percentile_NY_2018........... [RUN]
2021-02-15 02:27:29.047953 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_NY_2018".
2021-02-15 02:27:29.048141 (Thread-1): Compiling model.dbt_income_project.acs_percentile_NY_2018
2021-02-15 02:27:29.051134 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51570), raddr=('172.217.10.106', 443)>
2021-02-15 02:27:29.051749 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51571), raddr=('142.250.64.74', 443)>
2021-02-15 02:27:29.057544 (Thread-1): Writing injected SQL for node "model.dbt_income_project.acs_percentile_NY_2018"
2021-02-15 02:27:29.058298 (Thread-1): finished collecting timing info
2021-02-15 02:27:29.066030 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.acs_percentile_NY_2018"
2021-02-15 02:27:29.066901 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:27:29.074064 (Thread-1): On model.dbt_income_project.acs_percentile_NY_2018: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.acs_percentile_NY_2018"} */


  create or replace view `dbt-income`.`dbt_shafali`.`acs_percentile_NY_2018`
  OPTIONS()
  as WITH acs_2018 AS (
    SELECT
        geo_id,
        median_income AS income_2018,
    FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
  ),

median_income_in_us_2018 AS(
 
    SELECT
    region, MAX(median) as median_income_in_US_2018
    FROM(
        SELECT "US" AS region,
        PERCENTILE_CONT( median_income, 0.5) 
            OVER ()AS median
        FROM bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr
    )
    AS tmp
    GROUP BY region
    
),

mean_income_in_us_2018 AS(
    SELECT 
     "US" AS region,AVG(median_income) AS mean_income_in_us_2018
     FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
),
acs_2018_with_statecode AS (
    SELECT
        geo_id,
        income_2018,
        geo.state_code
    FROM
        acs_2018 a18
    JOIN
        `bigquery-public-data.geo_us_boundaries.zip_codes` geo
    ON
        a18.geo_id = geo.zip_code 
    WHERE geo.state_code = 'NY' OR geo.state_code = 'CA' OR geo.state_code = 'TX' OR geo.state_code = 'FL'
),

median_income_state_2018 AS(
    SELECT
    state_code, MAX(median) as median_income_2018
    FROM(
        SELECT state_code,
        PERCENTILE_CONT( income_2018, 0.5) 
            OVER (PARTITION BY state_code)AS median
        FROM acs_2018_with_statecode
    )
    AS tmp
    GROUP BY state_code
),

mean_income_state_2018 AS(
    SELECT
    state_code,
     AVG(income_2018) AS mean_income_in_2018,

    FROM
    acs_2018_with_statecode
    
    GROUP BY
    state_code
),
 
mean_median_income_state_2018 AS(

    SELECT mean_income_state_2018.state_code, mean_income_in_2018, median_income_state_2018.median_income_2018 FROM mean_income_state_2018 
    INNER JOIN  median_income_state_2018 
    ON mean_income_state_2018.state_code = median_income_state_2018.state_code
 
),


mean_median_income_us_2018 AS(
    SELECT  median_income_in_us_2018.region,mean_income_in_us_2018.mean_income_in_US_2018, median_income_in_us_2018.median_income_in_US_2018 FROM median_income_in_us_2018 
    INNER JOIN  mean_income_in_us_2018  
    ON mean_income_in_us_2018.region = median_income_in_us_2018.region
 
)


SELECT  
  percentiles[offset(10)] as p10,
  percentiles[offset(25)] as p25,
  percentiles[offset(50)] as p50,
  percentiles[offset(75)] as p75,
  percentiles[offset(90)] as p90,
FROM (
  SELECT approx_quantiles(income_2018 , 100) percentiles
    FROM (
        SELECT state_code, income_2018 
        FROM acs_2018_with_statecode
        WHERE state_code = 'NY'
    ) AS income
);


2021-02-15 02:27:30.060420 (Thread-1): finished collecting timing info
2021-02-15 02:27:30.062746 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd5111fd0-4708-451f-b17d-a875d44b5784', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d44ac0>]}
2021-02-15 02:27:30.064205 (Thread-1): 21:27:30 | 5 of 8 OK created view model dbt_shafali.acs_percentile_NY_2018...... [OK in 1.01s]
2021-02-15 02:27:30.064406 (Thread-1): Finished running node model.dbt_income_project.acs_percentile_NY_2018
2021-02-15 02:27:30.064854 (Thread-1): Began running node model.dbt_income_project.acs_percentile_TX_2018
2021-02-15 02:27:30.066271 (Thread-1): 21:27:30 | 6 of 8 START view model dbt_shafali.acs_percentile_TX_2018........... [RUN]
2021-02-15 02:27:30.066739 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_TX_2018".
2021-02-15 02:27:30.066915 (Thread-1): Compiling model.dbt_income_project.acs_percentile_TX_2018
2021-02-15 02:27:30.074488 (Thread-1): Writing injected SQL for node "model.dbt_income_project.acs_percentile_TX_2018"
2021-02-15 02:27:30.075199 (Thread-1): finished collecting timing info
2021-02-15 02:27:30.078340 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51565), raddr=('172.217.10.106', 443)>
2021-02-15 02:27:30.079055 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51566), raddr=('142.250.64.74', 443)>
2021-02-15 02:27:30.079564 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51568), raddr=('142.250.64.74', 443)>
2021-02-15 02:27:30.080020 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51567), raddr=('172.217.10.106', 443)>
2021-02-15 02:27:30.086726 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51572), raddr=('172.217.10.106', 443)>
2021-02-15 02:27:30.087379 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51573), raddr=('142.250.64.74', 443)>
2021-02-15 02:27:30.094518 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.acs_percentile_TX_2018"
2021-02-15 02:27:30.095513 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:27:30.103444 (Thread-1): On model.dbt_income_project.acs_percentile_TX_2018: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.acs_percentile_TX_2018"} */


  create or replace view `dbt-income`.`dbt_shafali`.`acs_percentile_TX_2018`
  OPTIONS()
  as WITH acs_2018 AS (
    SELECT
        geo_id,
        median_income AS income_2018,
    FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
  ),

median_income_in_us_2018 AS(
 
    SELECT
    region, MAX(median) as median_income_in_US_2018
    FROM(
        SELECT "US" AS region,
        PERCENTILE_CONT( median_income, 0.5) 
            OVER ()AS median
        FROM bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr
    )
    AS tmp
    GROUP BY region
    
),

mean_income_in_us_2018 AS(
    SELECT 
     "US" AS region,AVG(median_income) AS mean_income_in_us_2018
     FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
),
acs_2018_with_statecode AS (
    SELECT
        geo_id,
        income_2018,
        geo.state_code
    FROM
        acs_2018 a18
    JOIN
        `bigquery-public-data.geo_us_boundaries.zip_codes` geo
    ON
        a18.geo_id = geo.zip_code 
    WHERE geo.state_code = 'NY' OR geo.state_code = 'CA' OR geo.state_code = 'TX' OR geo.state_code = 'FL'
),

median_income_state_2018 AS(
    SELECT
    state_code, MAX(median) as median_income_2018
    FROM(
        SELECT state_code,
        PERCENTILE_CONT( income_2018, 0.5) 
            OVER (PARTITION BY state_code)AS median
        FROM acs_2018_with_statecode
    )
    AS tmp
    GROUP BY state_code
),

mean_income_state_2018 AS(
    SELECT
    state_code,
     AVG(income_2018) AS mean_income_in_2018,

    FROM
    acs_2018_with_statecode
    
    GROUP BY
    state_code
),
 
mean_median_income_state_2018 AS(

    SELECT mean_income_state_2018.state_code, mean_income_in_2018, median_income_state_2018.median_income_2018 FROM mean_income_state_2018 
    INNER JOIN  median_income_state_2018 
    ON mean_income_state_2018.state_code = median_income_state_2018.state_code
 
),


mean_median_income_us_2018 AS(
    SELECT  median_income_in_us_2018.region,mean_income_in_us_2018.mean_income_in_US_2018, median_income_in_us_2018.median_income_in_US_2018 FROM median_income_in_us_2018 
    INNER JOIN  mean_income_in_us_2018  
    ON mean_income_in_us_2018.region = median_income_in_us_2018.region
 
)


SELECT  
  percentiles[offset(10)] as p10,
  percentiles[offset(25)] as p25,
  percentiles[offset(50)] as p50,
  percentiles[offset(75)] as p75,
  percentiles[offset(90)] as p90,
FROM (
  SELECT approx_quantiles(income_2018 , 100) percentiles
    FROM (
        SELECT state_code, income_2018 
        FROM acs_2018_with_statecode
        WHERE state_code = 'TX'
    ) AS income
);


2021-02-15 02:27:31.076570 (Thread-1): finished collecting timing info
2021-02-15 02:27:31.078132 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd5111fd0-4708-451f-b17d-a875d44b5784', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ed68e0>]}
2021-02-15 02:27:31.080891 (Thread-1): 21:27:31 | 6 of 8 OK created view model dbt_shafali.acs_percentile_TX_2018...... [OK in 1.01s]
2021-02-15 02:27:31.081639 (Thread-1): Finished running node model.dbt_income_project.acs_percentile_TX_2018
2021-02-15 02:27:31.083997 (Thread-1): Began running node model.dbt_income_project.acs_percentile_US_2018
2021-02-15 02:27:31.085921 (Thread-1): 21:27:31 | 7 of 8 START view model dbt_shafali.acs_percentile_US_2018........... [RUN]
2021-02-15 02:27:31.086883 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_US_2018".
2021-02-15 02:27:31.087187 (Thread-1): Compiling model.dbt_income_project.acs_percentile_US_2018
2021-02-15 02:27:31.094819 (Thread-1): Writing injected SQL for node "model.dbt_income_project.acs_percentile_US_2018"
2021-02-15 02:27:31.100709 (Thread-1): finished collecting timing info
2021-02-15 02:27:31.110952 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.acs_percentile_US_2018"
2021-02-15 02:27:31.112142 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:27:31.123048 (Thread-1): On model.dbt_income_project.acs_percentile_US_2018: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.acs_percentile_US_2018"} */


  create or replace view `dbt-income`.`dbt_shafali`.`acs_percentile_US_2018`
  OPTIONS()
  as SELECT  
  percentiles[offset(10)] as p10,
  percentiles[offset(25)] as p25,
  percentiles[offset(50)] as p50,
  percentiles[offset(75)] as p75,
  percentiles[offset(90)] as p90,
from (
  select approx_quantiles(median_income, 100) percentiles
  from  `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
);


2021-02-15 02:27:31.938199 (Thread-1): finished collecting timing info
2021-02-15 02:27:31.940071 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd5111fd0-4708-451f-b17d-a875d44b5784', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112844700>]}
2021-02-15 02:27:31.942580 (Thread-1): 21:27:31 | 7 of 8 OK created view model dbt_shafali.acs_percentile_US_2018...... [OK in 0.85s]
2021-02-15 02:27:31.943086 (Thread-1): Finished running node model.dbt_income_project.acs_percentile_US_2018
2021-02-15 02:27:31.943512 (Thread-1): Began running node model.dbt_income_project.my_second_dbt_model
2021-02-15 02:27:31.946547 (Thread-1): 21:27:31 | 8 of 8 START view model dbt_shafali.my_second_dbt_model.............. [RUN]
2021-02-15 02:27:31.947286 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.my_second_dbt_model".
2021-02-15 02:27:31.947616 (Thread-1): Compiling model.dbt_income_project.my_second_dbt_model
2021-02-15 02:27:31.963648 (Thread-1): Writing injected SQL for node "model.dbt_income_project.my_second_dbt_model"
2021-02-15 02:27:31.964308 (Thread-1): finished collecting timing info
2021-02-15 02:27:31.971169 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.my_second_dbt_model"
2021-02-15 02:27:31.971943 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:27:31.976985 (Thread-1): On model.dbt_income_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.my_second_dbt_model"} */


  create or replace view `dbt-income`.`dbt_shafali`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `dbt-income`.`dbt_shafali`.`my_first_dbt_model`
where id = 1;


2021-02-15 02:27:32.921188 (Thread-1): finished collecting timing info
2021-02-15 02:27:32.922791 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd5111fd0-4708-451f-b17d-a875d44b5784', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1130ead90>]}
2021-02-15 02:27:32.924685 (Thread-1): 21:27:32 | 8 of 8 OK created view model dbt_shafali.my_second_dbt_model......... [OK in 0.98s]
2021-02-15 02:27:32.924959 (Thread-1): Finished running node model.dbt_income_project.my_second_dbt_model
2021-02-15 02:27:32.926811 (MainThread): Acquiring new bigquery connection "master".
2021-02-15 02:27:32.927585 (MainThread): 21:27:32 | 
2021-02-15 02:27:32.927813 (MainThread): 21:27:32 | Finished running 1 table model, 7 view models in 9.63s.
2021-02-15 02:27:32.927954 (MainThread): Connection 'master' was properly closed.
2021-02-15 02:27:32.928130 (MainThread): Connection 'model.dbt_income_project.my_second_dbt_model' was properly closed.
2021-02-15 02:27:32.962085 (MainThread): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51580), raddr=('172.217.10.106', 443)>
2021-02-15 02:27:32.962636 (MainThread): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51581), raddr=('142.250.64.74', 443)>
2021-02-15 02:27:33.004308 (MainThread): 
2021-02-15 02:27:33.004529 (MainThread): Completed successfully
2021-02-15 02:27:33.004796 (MainThread): 
Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
2021-02-15 02:27:33.005275 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1128671c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113008a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ea9280>]}
2021-02-15 02:27:33.005562 (MainThread): Flushing usage events
2021-02-15 02:35:40.220530 (MainThread): Running with dbt=0.19.0
2021-02-15 02:35:41.430216 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/shafaligupta/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-02-15 02:35:41.432777 (MainThread): Tracking: tracking
2021-02-15 02:35:41.450452 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073d68e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073e65b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073e6490>]}
2021-02-15 02:35:41.493597 (MainThread): Partial parsing not enabled
2021-02-15 02:35:41.496750 (MainThread): Parsing macros/etc.sql
2021-02-15 02:35:41.502024 (MainThread): Parsing macros/catalog.sql
2021-02-15 02:35:41.514232 (MainThread): Parsing macros/adapters.sql
2021-02-15 02:35:41.556191 (MainThread): Parsing macros/materializations/seed.sql
2021-02-15 02:35:41.563561 (MainThread): Parsing macros/materializations/view.sql
2021-02-15 02:35:41.569773 (MainThread): Parsing macros/materializations/table.sql
2021-02-15 02:35:41.592928 (MainThread): Parsing macros/materializations/copy.sql
2021-02-15 02:35:41.602068 (MainThread): Parsing macros/materializations/incremental.sql
2021-02-15 02:35:41.627325 (MainThread): Parsing macros/materializations/snapshot.sql
2021-02-15 02:35:41.634893 (MainThread): Parsing macros/core.sql
2021-02-15 02:35:41.646847 (MainThread): Parsing macros/materializations/helpers.sql
2021-02-15 02:35:41.663657 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-02-15 02:35:41.667515 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-02-15 02:35:41.697147 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-02-15 02:35:41.747648 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-02-15 02:35:41.781428 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-02-15 02:35:41.786624 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-02-15 02:35:41.798393 (MainThread): Parsing macros/materializations/common/merge.sql
2021-02-15 02:35:41.822436 (MainThread): Parsing macros/materializations/table/table.sql
2021-02-15 02:35:41.835170 (MainThread): Parsing macros/materializations/view/view.sql
2021-02-15 02:35:41.846618 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-02-15 02:35:41.856672 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-02-15 02:35:41.860138 (MainThread): Parsing macros/etc/query.sql
2021-02-15 02:35:41.863669 (MainThread): Parsing macros/etc/is_incremental.sql
2021-02-15 02:35:41.868394 (MainThread): Parsing macros/etc/datetime.sql
2021-02-15 02:35:41.885447 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-02-15 02:35:41.890927 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-02-15 02:35:41.895589 (MainThread): Parsing macros/adapters/common.sql
2021-02-15 02:35:41.962351 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-02-15 02:35:41.966952 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-02-15 02:35:41.971532 (MainThread): Parsing macros/schema_tests/unique.sql
2021-02-15 02:35:41.975836 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-02-15 02:35:41.989496 (MainThread): Partial parsing not enabled
2021-02-15 02:35:42.060143 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.percentile_2013_2018".
2021-02-15 02:35:42.093755 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.mean_median_US_2013_2018".
2021-02-15 02:35:42.114826 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_US_2018".
2021-02-15 02:35:42.137975 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_FL_2018".
2021-02-15 02:35:42.163822 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_median_and_mean_US_and_states_2018".
2021-02-15 02:35:42.186967 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_TX_2018".
2021-02-15 02:35:42.209397 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_CA_2018".
2021-02-15 02:35:42.279848 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_NY_2018".
2021-02-15 02:35:42.594552 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0e8193e5-a1d2-47d8-955d-6dc8c00dc798', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10762b820>]}
2021-02-15 02:35:42.667585 (MainThread): Found 8 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-02-15 02:35:42.668822 (MainThread): 
2021-02-15 02:35:42.669352 (MainThread): Acquiring new bigquery connection "master".
2021-02-15 02:35:42.685817 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_dbt-income".
2021-02-15 02:35:42.686422 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-02-15 02:35:43.159964 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_dbt-income_dbt_shafali".
2021-02-15 02:35:43.160295 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-02-15 02:35:43.165392 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-02-15 02:35:43.601291 (MainThread): 21:35:43 | Concurrency: 1 threads (target='dev')
2021-02-15 02:35:43.601724 (MainThread): 21:35:43 | 
2021-02-15 02:35:43.606179 (Thread-1): Began running node model.dbt_income_project.acs_median_and_mean_US_and_states_2018
2021-02-15 02:35:43.607591 (Thread-1): 21:35:43 | 1 of 8 START view model dbt_shafali.acs_median_and_mean_US_and_states_2018 [RUN]
2021-02-15 02:35:43.608067 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.acs_median_and_mean_US_and_states_2018".
2021-02-15 02:35:43.608248 (Thread-1): Compiling model.dbt_income_project.acs_median_and_mean_US_and_states_2018
2021-02-15 02:35:43.625756 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51715), raddr=('172.217.12.170', 443)>
2021-02-15 02:35:43.626303 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51716), raddr=('142.250.64.106', 443)>
2021-02-15 02:35:43.626703 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51719), raddr=('142.250.64.106', 443)>
2021-02-15 02:35:43.627070 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51717), raddr=('172.217.12.170', 443)>
2021-02-15 02:35:43.632756 (Thread-1): Writing injected SQL for node "model.dbt_income_project.acs_median_and_mean_US_and_states_2018"
2021-02-15 02:35:43.633579 (Thread-1): finished collecting timing info
2021-02-15 02:35:43.685224 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.acs_median_and_mean_US_and_states_2018"
2021-02-15 02:35:43.686178 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:35:43.697140 (Thread-1): On model.dbt_income_project.acs_median_and_mean_US_and_states_2018: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.acs_median_and_mean_US_and_states_2018"} */


  create or replace view `dbt-income`.`dbt_shafali`.`acs_median_and_mean_US_and_states_2018`
  OPTIONS()
  as # geo_id, income_2018
WITH acs_2018 AS (
    SELECT
        geo_id,
        median_income AS income_2018,
    FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
  ),
#median_income_us
median_income_in_us_2018 AS(
    SELECT
    region, MAX(median) as median_income_in_US_2018
    FROM(
        SELECT "US" AS region,
        PERCENTILE_CONT( median_income, 0.5) 
            OVER ()AS median
        FROM bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr
    )
    AS tmp
    GROUP BY region
),
#mean_income_us
mean_income_in_us_2018 AS(
    SELECT 
     "US" AS region,AVG(median_income) AS mean_income_in_us_2018
     FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
),
acs_2018_with_statecode AS (
    SELECT
        geo_id,
        income_2018,
        geo.state_code
    FROM
        acs_2018 a18
    JOIN
        `bigquery-public-data.geo_us_boundaries.zip_codes` geo
    ON
        a18.geo_id = geo.zip_code 
    WHERE geo.state_code = 'NY' OR geo.state_code = 'CA' OR geo.state_code = 'TX' OR geo.state_code = 'FL'
),
#state median income
median_income_state_2018 AS(
    SELECT
    state_code, MAX(median) as median_income_2018
    FROM(
        SELECT state_code,
        PERCENTILE_CONT( income_2018, 0.5) 
            OVER (PARTITION BY state_code)AS median
        FROM acs_2018_with_statecode
    )
    AS tmp
    GROUP BY state_code
),
#state mean income
mean_income_state_2018 AS(
    SELECT
    state_code,
     AVG(income_2018) AS mean_income_in_2018,
    FROM
    acs_2018_with_statecode
    GROUP BY
    state_code
),
# states median + mean 
mean_median_income_state_2018 AS(
    SELECT mean_income_state_2018.state_code, mean_income_in_2018, median_income_state_2018.median_income_2018 FROM mean_income_state_2018 
    INNER JOIN  median_income_state_2018 
    ON mean_income_state_2018.state_code = median_income_state_2018.state_code
),
# US median + mean 
mean_median_income_us_2018 AS(
    SELECT median_income_in_us_2018.region,mean_income_in_us_2018.mean_income_in_US_2018, median_income_in_us_2018.median_income_in_US_2018 FROM median_income_in_us_2018 
    INNER JOIN  mean_income_in_us_2018  
    ON mean_income_in_us_2018.region = median_income_in_us_2018.region
),
state_us_mean_median_income_2018 AS(
    SELECT region, mean_income_in_US_2018, median_income_in_US_2018 
    FROM mean_median_income_us_2018
    UNION ALL
    SELECT state_code, mean_income_in_2018, median_income_2018
    FROM 
    mean_median_income_state_2018
)
SELECT * FROM state_us_mean_median_income_2018;


2021-02-15 02:35:45.096093 (Thread-1): finished collecting timing info
2021-02-15 02:35:45.097544 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0e8193e5-a1d2-47d8-955d-6dc8c00dc798', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10759fe50>]}
2021-02-15 02:35:45.099149 (Thread-1): 21:35:45 | 1 of 8 OK created view model dbt_shafali.acs_median_and_mean_US_and_states_2018 [OK in 1.49s]
2021-02-15 02:35:45.099896 (Thread-1): Finished running node model.dbt_income_project.acs_median_and_mean_US_and_states_2018
2021-02-15 02:35:45.100762 (Thread-1): Began running node model.dbt_income_project.acs_percentile_CA_2018
2021-02-15 02:35:45.103082 (Thread-1): 21:35:45 | 2 of 8 START view model dbt_shafali.acs_percentile_CA_2018........... [RUN]
2021-02-15 02:35:45.103618 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_CA_2018".
2021-02-15 02:35:45.103800 (Thread-1): Compiling model.dbt_income_project.acs_percentile_CA_2018
2021-02-15 02:35:45.112107 (Thread-1): Writing injected SQL for node "model.dbt_income_project.acs_percentile_CA_2018"
2021-02-15 02:35:45.115202 (Thread-1): finished collecting timing info
2021-02-15 02:35:45.127385 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.acs_percentile_CA_2018"
2021-02-15 02:35:45.128125 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:35:45.135216 (Thread-1): On model.dbt_income_project.acs_percentile_CA_2018: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.acs_percentile_CA_2018"} */


  create or replace view `dbt-income`.`dbt_shafali`.`acs_percentile_CA_2018`
  OPTIONS()
  as WITH acs_2018 AS (
    SELECT
        geo_id,
        median_income AS income_2018,
    FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
  ),

median_income_in_us_2018 AS(
 
    SELECT
    region, MAX(median) as median_income_in_US_2018
    FROM(
        SELECT "US" AS region,
        PERCENTILE_CONT( median_income, 0.5) 
            OVER ()AS median
        FROM bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr
    )
    AS tmp
    GROUP BY region
    
),

mean_income_in_us_2018 AS(
    SELECT 
     "US" AS region,AVG(median_income) AS mean_income_in_us_2018
     FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
),
acs_2018_with_statecode AS (
    SELECT
        geo_id,
        income_2018,
        geo.state_code
    FROM
        acs_2018 a18
    JOIN
        `bigquery-public-data.geo_us_boundaries.zip_codes` geo
    ON
        a18.geo_id = geo.zip_code 
    WHERE geo.state_code = 'NY' OR geo.state_code = 'CA' OR geo.state_code = 'TX' OR geo.state_code = 'FL'
),

median_income_state_2018 AS(
    SELECT
    state_code, MAX(median) as median_income_2018
    FROM(
        SELECT state_code,
        PERCENTILE_CONT( income_2018, 0.5) 
            OVER (PARTITION BY state_code)AS median
        FROM acs_2018_with_statecode
    )
    AS tmp
    GROUP BY state_code
),

mean_income_state_2018 AS(
    SELECT
    state_code,
     AVG(income_2018) AS mean_income_in_2018,

    FROM
    acs_2018_with_statecode
    
    GROUP BY
    state_code
),
 
mean_median_income_state_2018 AS(

    SELECT mean_income_state_2018.state_code, mean_income_in_2018, median_income_state_2018.median_income_2018 FROM mean_income_state_2018 
    INNER JOIN  median_income_state_2018 
    ON mean_income_state_2018.state_code = median_income_state_2018.state_code
 
),


mean_median_income_us_2018 AS(
    SELECT  median_income_in_us_2018.region,mean_income_in_us_2018.mean_income_in_US_2018, median_income_in_us_2018.median_income_in_US_2018 FROM median_income_in_us_2018 
    INNER JOIN  mean_income_in_us_2018  
    ON mean_income_in_us_2018.region = median_income_in_us_2018.region
 
)


SELECT  
  percentiles[offset(10)] as p10,
  percentiles[offset(25)] as p25,
  percentiles[offset(50)] as p50,
  percentiles[offset(75)] as p75,
  percentiles[offset(90)] as p90,
FROM (
  SELECT approx_quantiles(income_2018 , 100) percentiles
    FROM (
        SELECT state_code, income_2018 
        FROM acs_2018_with_statecode
        WHERE state_code = 'CA'
    ) AS income
);


2021-02-15 02:35:46.017000 (Thread-1): finished collecting timing info
2021-02-15 02:35:46.017887 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0e8193e5-a1d2-47d8-955d-6dc8c00dc798', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076e12e0>]}
2021-02-15 02:35:46.019251 (Thread-1): 21:35:46 | 2 of 8 OK created view model dbt_shafali.acs_percentile_CA_2018...... [OK in 0.91s]
2021-02-15 02:35:46.019454 (Thread-1): Finished running node model.dbt_income_project.acs_percentile_CA_2018
2021-02-15 02:35:46.019691 (Thread-1): Began running node model.dbt_income_project.acs_percentile_FL_2018
2021-02-15 02:35:46.021545 (Thread-1): 21:35:46 | 3 of 8 START view model dbt_shafali.acs_percentile_FL_2018........... [RUN]
2021-02-15 02:35:46.022237 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_FL_2018".
2021-02-15 02:35:46.022484 (Thread-1): Compiling model.dbt_income_project.acs_percentile_FL_2018
2021-02-15 02:35:46.035803 (Thread-1): Writing injected SQL for node "model.dbt_income_project.acs_percentile_FL_2018"
2021-02-15 02:35:46.037060 (Thread-1): finished collecting timing info
2021-02-15 02:35:46.044521 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.acs_percentile_FL_2018"
2021-02-15 02:35:46.045470 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:35:46.052254 (Thread-1): On model.dbt_income_project.acs_percentile_FL_2018: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.acs_percentile_FL_2018"} */


  create or replace view `dbt-income`.`dbt_shafali`.`acs_percentile_FL_2018`
  OPTIONS()
  as WITH acs_2018 AS (
    SELECT
        geo_id,
        median_income AS income_2018,
    FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
  ),

median_income_in_us_2018 AS(
 
    SELECT
    region, MAX(median) as median_income_in_US_2018
    FROM(
        SELECT "US" AS region,
        PERCENTILE_CONT( median_income, 0.5) 
            OVER ()AS median
        FROM bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr
    )
    AS tmp
    GROUP BY region
    
),

mean_income_in_us_2018 AS(
    SELECT 
     "US" AS region,AVG(median_income) AS mean_income_in_us_2018
     FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
),
acs_2018_with_statecode AS (
    SELECT
        geo_id,
        income_2018,
        geo.state_code
    FROM
        acs_2018 a18
    JOIN
        `bigquery-public-data.geo_us_boundaries.zip_codes` geo
    ON
        a18.geo_id = geo.zip_code 
    WHERE geo.state_code = 'NY' OR geo.state_code = 'CA' OR geo.state_code = 'TX' OR geo.state_code = 'FL'
),

median_income_state_2018 AS(
    SELECT
    state_code, MAX(median) as median_income_2018
    FROM(
        SELECT state_code,
        PERCENTILE_CONT( income_2018, 0.5) 
            OVER (PARTITION BY state_code)AS median
        FROM acs_2018_with_statecode
    )
    AS tmp
    GROUP BY state_code
),

mean_income_state_2018 AS(
    SELECT
    state_code,
     AVG(income_2018) AS mean_income_in_2018,

    FROM
    acs_2018_with_statecode
    
    GROUP BY
    state_code
),
 
mean_median_income_state_2018 AS(

    SELECT mean_income_state_2018.state_code, mean_income_in_2018, median_income_state_2018.median_income_2018 FROM mean_income_state_2018 
    INNER JOIN  median_income_state_2018 
    ON mean_income_state_2018.state_code = median_income_state_2018.state_code
 
),


mean_median_income_us_2018 AS(
    SELECT  median_income_in_us_2018.region,mean_income_in_us_2018.mean_income_in_US_2018, median_income_in_us_2018.median_income_in_US_2018 FROM median_income_in_us_2018 
    INNER JOIN  mean_income_in_us_2018  
    ON mean_income_in_us_2018.region = median_income_in_us_2018.region
 
)


SELECT  
  percentiles[offset(10)] as p10,
  percentiles[offset(25)] as p25,
  percentiles[offset(50)] as p50,
  percentiles[offset(75)] as p75,
  percentiles[offset(90)] as p90,
FROM (
  SELECT approx_quantiles(income_2018 , 100) percentiles
    FROM (
        SELECT state_code, income_2018 
        FROM acs_2018_with_statecode
        WHERE state_code = 'FL'
    ) AS income
);


2021-02-15 02:35:47.097479 (Thread-1): finished collecting timing info
2021-02-15 02:35:47.099196 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0e8193e5-a1d2-47d8-955d-6dc8c00dc798', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107621370>]}
2021-02-15 02:35:47.102012 (Thread-1): 21:35:47 | 3 of 8 OK created view model dbt_shafali.acs_percentile_FL_2018...... [OK in 1.08s]
2021-02-15 02:35:47.102405 (Thread-1): Finished running node model.dbt_income_project.acs_percentile_FL_2018
2021-02-15 02:35:47.102689 (Thread-1): Began running node model.dbt_income_project.acs_percentile_NY_2018
2021-02-15 02:35:47.105677 (Thread-1): 21:35:47 | 4 of 8 START view model dbt_shafali.acs_percentile_NY_2018........... [RUN]
2021-02-15 02:35:47.106332 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_NY_2018".
2021-02-15 02:35:47.106633 (Thread-1): Compiling model.dbt_income_project.acs_percentile_NY_2018
2021-02-15 02:35:47.118293 (Thread-1): Writing injected SQL for node "model.dbt_income_project.acs_percentile_NY_2018"
2021-02-15 02:35:47.119014 (Thread-1): finished collecting timing info
2021-02-15 02:35:47.126106 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.acs_percentile_NY_2018"
2021-02-15 02:35:47.126798 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:35:47.132468 (Thread-1): On model.dbt_income_project.acs_percentile_NY_2018: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.acs_percentile_NY_2018"} */


  create or replace view `dbt-income`.`dbt_shafali`.`acs_percentile_NY_2018`
  OPTIONS()
  as WITH acs_2018 AS (
    SELECT
        geo_id,
        median_income AS income_2018,
    FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
  ),

median_income_in_us_2018 AS(
 
    SELECT
    region, MAX(median) as median_income_in_US_2018
    FROM(
        SELECT "US" AS region,
        PERCENTILE_CONT( median_income, 0.5) 
            OVER ()AS median
        FROM bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr
    )
    AS tmp
    GROUP BY region
    
),

mean_income_in_us_2018 AS(
    SELECT 
     "US" AS region,AVG(median_income) AS mean_income_in_us_2018
     FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
),
acs_2018_with_statecode AS (
    SELECT
        geo_id,
        income_2018,
        geo.state_code
    FROM
        acs_2018 a18
    JOIN
        `bigquery-public-data.geo_us_boundaries.zip_codes` geo
    ON
        a18.geo_id = geo.zip_code 
    WHERE geo.state_code = 'NY' OR geo.state_code = 'CA' OR geo.state_code = 'TX' OR geo.state_code = 'FL'
),

median_income_state_2018 AS(
    SELECT
    state_code, MAX(median) as median_income_2018
    FROM(
        SELECT state_code,
        PERCENTILE_CONT( income_2018, 0.5) 
            OVER (PARTITION BY state_code)AS median
        FROM acs_2018_with_statecode
    )
    AS tmp
    GROUP BY state_code
),

mean_income_state_2018 AS(
    SELECT
    state_code,
     AVG(income_2018) AS mean_income_in_2018,

    FROM
    acs_2018_with_statecode
    
    GROUP BY
    state_code
),
 
mean_median_income_state_2018 AS(

    SELECT mean_income_state_2018.state_code, mean_income_in_2018, median_income_state_2018.median_income_2018 FROM mean_income_state_2018 
    INNER JOIN  median_income_state_2018 
    ON mean_income_state_2018.state_code = median_income_state_2018.state_code
 
),


mean_median_income_us_2018 AS(
    SELECT  median_income_in_us_2018.region,mean_income_in_us_2018.mean_income_in_US_2018, median_income_in_us_2018.median_income_in_US_2018 FROM median_income_in_us_2018 
    INNER JOIN  mean_income_in_us_2018  
    ON mean_income_in_us_2018.region = median_income_in_us_2018.region
 
)


SELECT  
  percentiles[offset(10)] as p10,
  percentiles[offset(25)] as p25,
  percentiles[offset(50)] as p50,
  percentiles[offset(75)] as p75,
  percentiles[offset(90)] as p90,
FROM (
  SELECT approx_quantiles(income_2018 , 100) percentiles
    FROM (
        SELECT state_code, income_2018 
        FROM acs_2018_with_statecode
        WHERE state_code = 'NY'
    ) AS income
);


2021-02-15 02:35:48.039698 (Thread-1): finished collecting timing info
2021-02-15 02:35:48.041073 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0e8193e5-a1d2-47d8-955d-6dc8c00dc798', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107621850>]}
2021-02-15 02:35:48.042734 (Thread-1): 21:35:48 | 4 of 8 OK created view model dbt_shafali.acs_percentile_NY_2018...... [OK in 0.93s]
2021-02-15 02:35:48.042964 (Thread-1): Finished running node model.dbt_income_project.acs_percentile_NY_2018
2021-02-15 02:35:48.043251 (Thread-1): Began running node model.dbt_income_project.acs_percentile_TX_2018
2021-02-15 02:35:48.044673 (Thread-1): 21:35:48 | 5 of 8 START view model dbt_shafali.acs_percentile_TX_2018........... [RUN]
2021-02-15 02:35:48.045166 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_TX_2018".
2021-02-15 02:35:48.045341 (Thread-1): Compiling model.dbt_income_project.acs_percentile_TX_2018
2021-02-15 02:35:48.049593 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51721), raddr=('172.217.12.170', 443)>
2021-02-15 02:35:48.050187 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51722), raddr=('142.250.64.106', 443)>
2021-02-15 02:35:48.050641 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51726), raddr=('172.217.12.170', 443)>
2021-02-15 02:35:48.051188 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51727), raddr=('142.250.64.106', 443)>
2021-02-15 02:35:48.051679 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51729), raddr=('142.250.64.106', 443)>
2021-02-15 02:35:48.052113 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51728), raddr=('172.217.12.170', 443)>
2021-02-15 02:35:48.052513 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51730), raddr=('172.217.12.170', 443)>
2021-02-15 02:35:48.052861 (Thread-1): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51731), raddr=('142.250.64.106', 443)>
2021-02-15 02:35:48.058747 (Thread-1): Writing injected SQL for node "model.dbt_income_project.acs_percentile_TX_2018"
2021-02-15 02:35:48.059433 (Thread-1): finished collecting timing info
2021-02-15 02:35:48.067215 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.acs_percentile_TX_2018"
2021-02-15 02:35:48.067893 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:35:48.074579 (Thread-1): On model.dbt_income_project.acs_percentile_TX_2018: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.acs_percentile_TX_2018"} */


  create or replace view `dbt-income`.`dbt_shafali`.`acs_percentile_TX_2018`
  OPTIONS()
  as WITH acs_2018 AS (
    SELECT
        geo_id,
        median_income AS income_2018,
    FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
  ),

median_income_in_us_2018 AS(
 
    SELECT
    region, MAX(median) as median_income_in_US_2018
    FROM(
        SELECT "US" AS region,
        PERCENTILE_CONT( median_income, 0.5) 
            OVER ()AS median
        FROM bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr
    )
    AS tmp
    GROUP BY region
    
),

mean_income_in_us_2018 AS(
    SELECT 
     "US" AS region,AVG(median_income) AS mean_income_in_us_2018
     FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
),
acs_2018_with_statecode AS (
    SELECT
        geo_id,
        income_2018,
        geo.state_code
    FROM
        acs_2018 a18
    JOIN
        `bigquery-public-data.geo_us_boundaries.zip_codes` geo
    ON
        a18.geo_id = geo.zip_code 
    WHERE geo.state_code = 'NY' OR geo.state_code = 'CA' OR geo.state_code = 'TX' OR geo.state_code = 'FL'
),

median_income_state_2018 AS(
    SELECT
    state_code, MAX(median) as median_income_2018
    FROM(
        SELECT state_code,
        PERCENTILE_CONT( income_2018, 0.5) 
            OVER (PARTITION BY state_code)AS median
        FROM acs_2018_with_statecode
    )
    AS tmp
    GROUP BY state_code
),

mean_income_state_2018 AS(
    SELECT
    state_code,
     AVG(income_2018) AS mean_income_in_2018,

    FROM
    acs_2018_with_statecode
    
    GROUP BY
    state_code
),
 
mean_median_income_state_2018 AS(

    SELECT mean_income_state_2018.state_code, mean_income_in_2018, median_income_state_2018.median_income_2018 FROM mean_income_state_2018 
    INNER JOIN  median_income_state_2018 
    ON mean_income_state_2018.state_code = median_income_state_2018.state_code
 
),


mean_median_income_us_2018 AS(
    SELECT  median_income_in_us_2018.region,mean_income_in_us_2018.mean_income_in_US_2018, median_income_in_us_2018.median_income_in_US_2018 FROM median_income_in_us_2018 
    INNER JOIN  mean_income_in_us_2018  
    ON mean_income_in_us_2018.region = median_income_in_us_2018.region
 
)


SELECT  
  percentiles[offset(10)] as p10,
  percentiles[offset(25)] as p25,
  percentiles[offset(50)] as p50,
  percentiles[offset(75)] as p75,
  percentiles[offset(90)] as p90,
FROM (
  SELECT approx_quantiles(income_2018 , 100) percentiles
    FROM (
        SELECT state_code, income_2018 
        FROM acs_2018_with_statecode
        WHERE state_code = 'TX'
    ) AS income
);


2021-02-15 02:35:49.146313 (Thread-1): finished collecting timing info
2021-02-15 02:35:49.147650 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0e8193e5-a1d2-47d8-955d-6dc8c00dc798', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109805cd0>]}
2021-02-15 02:35:49.149516 (Thread-1): 21:35:49 | 5 of 8 OK created view model dbt_shafali.acs_percentile_TX_2018...... [OK in 1.10s]
2021-02-15 02:35:49.149742 (Thread-1): Finished running node model.dbt_income_project.acs_percentile_TX_2018
2021-02-15 02:35:49.149961 (Thread-1): Began running node model.dbt_income_project.acs_percentile_US_2018
2021-02-15 02:35:49.151391 (Thread-1): 21:35:49 | 6 of 8 START view model dbt_shafali.acs_percentile_US_2018........... [RUN]
2021-02-15 02:35:49.151920 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_US_2018".
2021-02-15 02:35:49.152098 (Thread-1): Compiling model.dbt_income_project.acs_percentile_US_2018
2021-02-15 02:35:49.159739 (Thread-1): Writing injected SQL for node "model.dbt_income_project.acs_percentile_US_2018"
2021-02-15 02:35:49.160465 (Thread-1): finished collecting timing info
2021-02-15 02:35:49.167878 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.acs_percentile_US_2018"
2021-02-15 02:35:49.168775 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:35:49.183132 (Thread-1): On model.dbt_income_project.acs_percentile_US_2018: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.acs_percentile_US_2018"} */


  create or replace view `dbt-income`.`dbt_shafali`.`acs_percentile_US_2018`
  OPTIONS()
  as SELECT  
  percentiles[offset(10)] as p10,
  percentiles[offset(25)] as p25,
  percentiles[offset(50)] as p50,
  percentiles[offset(75)] as p75,
  percentiles[offset(90)] as p90,
from (
  select approx_quantiles(median_income, 100) percentiles
  from  `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
);


2021-02-15 02:35:50.216071 (Thread-1): finished collecting timing info
2021-02-15 02:35:50.218313 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0e8193e5-a1d2-47d8-955d-6dc8c00dc798', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107621c10>]}
2021-02-15 02:35:50.220033 (Thread-1): 21:35:50 | 6 of 8 OK created view model dbt_shafali.acs_percentile_US_2018...... [OK in 1.07s]
2021-02-15 02:35:50.220401 (Thread-1): Finished running node model.dbt_income_project.acs_percentile_US_2018
2021-02-15 02:35:50.220753 (Thread-1): Began running node model.dbt_income_project.mean_median_US_2013_2018
2021-02-15 02:35:50.222283 (Thread-1): 21:35:50 | 7 of 8 START view model dbt_shafali.mean_median_US_2013_2018......... [RUN]
2021-02-15 02:35:50.222880 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.mean_median_US_2013_2018".
2021-02-15 02:35:50.223087 (Thread-1): Compiling model.dbt_income_project.mean_median_US_2013_2018
2021-02-15 02:35:50.230179 (Thread-1): Writing injected SQL for node "model.dbt_income_project.mean_median_US_2013_2018"
2021-02-15 02:35:50.230990 (Thread-1): finished collecting timing info
2021-02-15 02:35:50.236938 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.mean_median_US_2013_2018"
2021-02-15 02:35:50.237787 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:35:50.243416 (Thread-1): On model.dbt_income_project.mean_median_US_2013_2018: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.mean_median_US_2013_2018"} */


  create or replace view `dbt-income`.`dbt_shafali`.`mean_median_US_2013_2018`
  OPTIONS()
  as WITH 
acs_2013 AS (
  SELECT geo_id, median_income AS income_2013
  FROM `bigquery-public-data.census_bureau_acs.zip_codes_2013_5yr`  
),
acs_2018 AS (
  SELECT geo_id, median_income AS income_2018
  FROM `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr`  
), 
acs_2013_2018 AS(
    SELECT acs_2013.geo_id, income_2013, income_2018
    FROM 
    acs_2013 
    FULL JOIN 
    acs_2018
    ON 
    acs_2013.geo_id =acs_2018.geo_id
),
# mean
mean_income_2013_2018 AS( 
    SELECT "2013-2018"AS years, AVG(income_2013) AS mean_income_2013, AVG(income_2018)AS mean_income_2018
    FROM acs_2013_2018
),
# median 
median_income_2013_2018 AS( 
    SELECT "2013-2018"AS years, PERCENTILE_CONT(income_2013, 0.5) OVER() AS median_income_2013,
    PERCENTILE_CONT(income_2018, 0.5) OVER() AS median_income_2018
    FROM acs_2013_2018
    LIMIT 1
),
# median+mean
mean_median_income_2013_2018 AS(
    SELECT mean.years, mean_income_2013, median_income_2013,mean_income_2018, median_income_2018 
    FROM (
      mean_income_2013_2018 mean
      JOIN 
      median_income_2013_2018 median
      ON 
      mean.years = median.years
    )
)
SELECT * FROM mean_median_income_2013_2018;


2021-02-15 02:35:51.224863 (Thread-1): finished collecting timing info
2021-02-15 02:35:51.225838 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0e8193e5-a1d2-47d8-955d-6dc8c00dc798', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077caee0>]}
2021-02-15 02:35:51.228634 (Thread-1): 21:35:51 | 7 of 8 OK created view model dbt_shafali.mean_median_US_2013_2018.... [OK in 1.00s]
2021-02-15 02:35:51.229129 (Thread-1): Finished running node model.dbt_income_project.mean_median_US_2013_2018
2021-02-15 02:35:51.229460 (Thread-1): Began running node model.dbt_income_project.percentile_2013_2018
2021-02-15 02:35:51.232138 (Thread-1): 21:35:51 | 8 of 8 START view model dbt_shafali.percentile_2013_2018............. [RUN]
2021-02-15 02:35:51.233168 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.percentile_2013_2018".
2021-02-15 02:35:51.233436 (Thread-1): Compiling model.dbt_income_project.percentile_2013_2018
2021-02-15 02:35:51.237196 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51736), raddr=('172.217.12.170', 443)>
2021-02-15 02:35:51.237998 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51737), raddr=('142.250.64.106', 443)>
2021-02-15 02:35:51.248466 (Thread-1): Writing injected SQL for node "model.dbt_income_project.percentile_2013_2018"
2021-02-15 02:35:51.249449 (Thread-1): finished collecting timing info
2021-02-15 02:35:51.261100 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.percentile_2013_2018"
2021-02-15 02:35:51.262042 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 02:35:51.270604 (Thread-1): On model.dbt_income_project.percentile_2013_2018: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.percentile_2013_2018"} */


  create or replace view `dbt-income`.`dbt_shafali`.`percentile_2013_2018`
  OPTIONS()
  as WITH 
acs_2013 AS (
  SELECT geo_id, median_income AS income_2013
  FROM `bigquery-public-data.census_bureau_acs.zip_codes_2013_5yr`  
),
acs_2018 AS (
  SELECT  geo_id, median_income AS income_2018
  FROM `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr`  
), 
acs_2013_2018 AS(
    SELECT  acs_2013.geo_id, income_2013, income_2018
    FROM 
    acs_2013 
    FULL JOIN 
    acs_2018
    ON 
    acs_2013.geo_id =acs_2018.geo_id
),
percentiles_2013 AS(
  SELECT  
    "2013" as year,
    percentiles[offset(10)] as p10,
    percentiles[offset(25)] as p25,
    percentiles[offset(50)] as p50,
    percentiles[offset(75)] as p75,
    percentiles[offset(90)] as p90,
  from (
    select approx_quantiles(income_2013, 100) percentiles
    from  acs_2013_2018
  )
),
percentiles_2018 AS(
  SELECT  
    "2018" as year,
    percentiles[offset(10)] as p10,
    percentiles[offset(25)] as p25,
    percentiles[offset(50)] as p50,
    percentiles[offset(75)] as p75,
    percentiles[offset(90)] as p90,
  from (
    select approx_quantiles(income_2018, 100) percentiles
    from  acs_2013_2018
  )
)

SELECT * FROM 
  (
    SELECT year, p10, p25, p50, p75, p90
    FROM 
    percentiles_2013
    UNION ALL
    SELECT year, p10, p25, p50, p75, p90 
    FROM percentiles_2018
  ) percentiles_2013_2018;


2021-02-15 02:35:52.219495 (Thread-1): finished collecting timing info
2021-02-15 02:35:52.220681 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0e8193e5-a1d2-47d8-955d-6dc8c00dc798', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107621be0>]}
2021-02-15 02:35:52.222518 (Thread-1): 21:35:52 | 8 of 8 OK created view model dbt_shafali.percentile_2013_2018........ [OK in 0.99s]
2021-02-15 02:35:52.222813 (Thread-1): Finished running node model.dbt_income_project.percentile_2013_2018
2021-02-15 02:35:52.224305 (MainThread): Acquiring new bigquery connection "master".
2021-02-15 02:35:52.224766 (MainThread): 21:35:52 | 
2021-02-15 02:35:52.225155 (MainThread): 21:35:52 | Finished running 8 view models in 9.56s.
2021-02-15 02:35:52.225448 (MainThread): Connection 'master' was properly closed.
2021-02-15 02:35:52.225588 (MainThread): Connection 'model.dbt_income_project.percentile_2013_2018' was properly closed.
2021-02-15 02:35:52.301563 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51732), raddr=('172.217.12.170', 443)>
2021-02-15 02:35:52.302179 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51733), raddr=('142.250.64.106', 443)>
2021-02-15 02:35:52.302731 (MainThread): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51735), raddr=('142.250.64.106', 443)>
2021-02-15 02:35:52.303356 (MainThread): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51734), raddr=('172.217.12.170', 443)>
2021-02-15 02:35:52.310949 (MainThread): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51739), raddr=('172.217.12.170', 443)>
2021-02-15 02:35:52.311541 (MainThread): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 51740), raddr=('142.250.64.106', 443)>
2021-02-15 02:35:52.326148 (MainThread): 
2021-02-15 02:35:52.326433 (MainThread): Completed successfully
2021-02-15 02:35:52.326772 (MainThread): 
Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
2021-02-15 02:35:52.327106 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109892af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076b1700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076bf0a0>]}
2021-02-15 02:35:52.327380 (MainThread): Flushing usage events
2021-02-15 16:58:18.544365 (MainThread): Running with dbt=0.19.0
2021-02-15 16:58:20.653459 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/shafaligupta/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-02-15 16:58:20.656256 (MainThread): Tracking: tracking
2021-02-15 16:58:20.710765 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e25520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e32be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e32ac0>]}
2021-02-15 16:58:20.820526 (MainThread): Partial parsing not enabled
2021-02-15 16:58:20.832388 (MainThread): Parsing macros/etc.sql
2021-02-15 16:58:20.852721 (MainThread): Parsing macros/catalog.sql
2021-02-15 16:58:20.882363 (MainThread): Parsing macros/adapters.sql
2021-02-15 16:58:20.990344 (MainThread): Parsing macros/materializations/seed.sql
2021-02-15 16:58:21.008513 (MainThread): Parsing macros/materializations/view.sql
2021-02-15 16:58:21.021682 (MainThread): Parsing macros/materializations/table.sql
2021-02-15 16:58:21.081286 (MainThread): Parsing macros/materializations/copy.sql
2021-02-15 16:58:21.093271 (MainThread): Parsing macros/materializations/incremental.sql
2021-02-15 16:58:21.154255 (MainThread): Parsing macros/materializations/snapshot.sql
2021-02-15 16:58:21.170204 (MainThread): Parsing macros/core.sql
2021-02-15 16:58:21.183579 (MainThread): Parsing macros/materializations/helpers.sql
2021-02-15 16:58:21.222412 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-02-15 16:58:21.227779 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-02-15 16:58:21.384381 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-02-15 16:58:21.502513 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-02-15 16:58:21.564598 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-02-15 16:58:21.570810 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-02-15 16:58:21.593000 (MainThread): Parsing macros/materializations/common/merge.sql
2021-02-15 16:58:21.640311 (MainThread): Parsing macros/materializations/table/table.sql
2021-02-15 16:58:21.682953 (MainThread): Parsing macros/materializations/view/view.sql
2021-02-15 16:58:21.707893 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-02-15 16:58:21.724076 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-02-15 16:58:21.727694 (MainThread): Parsing macros/etc/query.sql
2021-02-15 16:58:21.734598 (MainThread): Parsing macros/etc/is_incremental.sql
2021-02-15 16:58:21.740292 (MainThread): Parsing macros/etc/datetime.sql
2021-02-15 16:58:21.766270 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-02-15 16:58:21.774777 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-02-15 16:58:21.782809 (MainThread): Parsing macros/adapters/common.sql
2021-02-15 16:58:21.907399 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-02-15 16:58:21.915181 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-02-15 16:58:21.921153 (MainThread): Parsing macros/schema_tests/unique.sql
2021-02-15 16:58:21.926646 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-02-15 16:58:21.976674 (MainThread): Partial parsing not enabled
2021-02-15 16:58:22.256980 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.percentile_2013_2018".
2021-02-15 16:58:22.353464 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.mean_median_US_2013_2018".
2021-02-15 16:58:22.385668 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_US_2018".
2021-02-15 16:58:22.427953 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_FL_2018".
2021-02-15 16:58:22.476985 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_median_and_mean_US_and_states_2018".
2021-02-15 16:58:22.516206 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_TX_2018".
2021-02-15 16:58:22.560438 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_CA_2018".
2021-02-15 16:58:22.712975 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_NY_2018".
2021-02-15 16:58:23.411070 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '822a58f3-0a72-4ecb-a9d8-e14126092096', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106079220>]}
2021-02-15 16:58:23.541592 (MainThread): Found 8 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-02-15 16:58:23.543036 (MainThread): 
2021-02-15 16:58:23.543886 (MainThread): Acquiring new bigquery connection "master".
2021-02-15 16:58:23.577540 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_dbt-income".
2021-02-15 16:58:23.578344 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-02-15 16:58:24.420983 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_dbt-income_dbt_shafali".
2021-02-15 16:58:24.421538 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-02-15 16:58:24.439068 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-02-15 16:58:25.080742 (MainThread): 11:58:25 | Concurrency: 1 threads (target='dev')
2021-02-15 16:58:25.081177 (MainThread): 11:58:25 | 
2021-02-15 16:58:25.098652 (Thread-1): Began running node model.dbt_income_project.acs_median_and_mean_US_and_states_2018
2021-02-15 16:58:25.106269 (Thread-1): 11:58:25 | 1 of 8 START view model dbt_shafali.acs_median_and_mean_US_and_states_2018 [RUN]
2021-02-15 16:58:25.107127 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.acs_median_and_mean_US_and_states_2018".
2021-02-15 16:58:25.108259 (Thread-1): Compiling model.dbt_income_project.acs_median_and_mean_US_and_states_2018
2021-02-15 16:58:25.167578 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 53702), raddr=('172.217.6.202', 443)>
2021-02-15 16:58:25.168191 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 53703), raddr=('172.217.3.106', 443)>
2021-02-15 16:58:25.168756 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 53705), raddr=('172.217.3.106', 443)>
2021-02-15 16:58:25.169480 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 53704), raddr=('172.217.6.202', 443)>
2021-02-15 16:58:25.186159 (Thread-1): Writing injected SQL for node "model.dbt_income_project.acs_median_and_mean_US_and_states_2018"
2021-02-15 16:58:25.188242 (Thread-1): finished collecting timing info
2021-02-15 16:58:25.319499 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.acs_median_and_mean_US_and_states_2018"
2021-02-15 16:58:25.322116 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 16:58:25.341942 (Thread-1): On model.dbt_income_project.acs_median_and_mean_US_and_states_2018: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.acs_median_and_mean_US_and_states_2018"} */


  create or replace view `dbt-income`.`dbt_shafali`.`acs_median_and_mean_US_and_states_2018`
  OPTIONS()
  as # geo_id, income_2018
WITH acs_2018 AS (
    SELECT
        geo_id,
        median_income AS income_2018,
    FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
  ),
#median_income_us
median_income_in_us_2018 AS(
    SELECT
    region, MAX(median) as median_income_in_US_2018
    FROM(
        SELECT "US" AS region,
        PERCENTILE_CONT( median_income, 0.5) 
            OVER ()AS median
        FROM bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr
    )
    AS tmp
    GROUP BY region
),
#mean_income_us
mean_income_in_us_2018 AS(
    SELECT 
     "US" AS region,AVG(median_income) AS mean_income_in_us_2018
     FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
),
acs_2018_with_statecode AS (
    SELECT
        geo_id,
        income_2018,
        geo.state_code
    FROM
        acs_2018 a18
    JOIN
        `bigquery-public-data.geo_us_boundaries.zip_codes` geo
    ON
        a18.geo_id = geo.zip_code 
    WHERE geo.state_code = 'NY' OR geo.state_code = 'CA' OR geo.state_code = 'TX' OR geo.state_code = 'FL'
),
#state median income
median_income_state_2018 AS(
    SELECT
    state_code, MAX(median) as median_income_2018
    FROM(
        SELECT state_code,
        PERCENTILE_CONT( income_2018, 0.5) 
            OVER (PARTITION BY state_code)AS median
        FROM acs_2018_with_statecode
    )
    AS tmp
    GROUP BY state_code
),
#state mean income
mean_income_state_2018 AS(
    SELECT
    state_code,
     AVG(income_2018) AS mean_income_in_2018,
    FROM
    acs_2018_with_statecode
    GROUP BY
    state_code
),
# states median + mean 
mean_median_income_state_2018 AS(
    SELECT mean_income_state_2018.state_code, mean_income_in_2018, median_income_state_2018.median_income_2018 FROM mean_income_state_2018 
    INNER JOIN  median_income_state_2018 
    ON mean_income_state_2018.state_code = median_income_state_2018.state_code
),
# US median + mean 
mean_median_income_us_2018 AS(
    SELECT median_income_in_us_2018.region,mean_income_in_us_2018.mean_income_in_US_2018, median_income_in_us_2018.median_income_in_US_2018 FROM median_income_in_us_2018 
    INNER JOIN  mean_income_in_us_2018  
    ON mean_income_in_us_2018.region = median_income_in_us_2018.region
),
state_us_mean_median_income_2018 AS(
    SELECT region, mean_income_in_US_2018, median_income_in_US_2018 
    FROM mean_median_income_us_2018
    UNION ALL
    SELECT state_code, mean_income_in_2018, median_income_2018
    FROM 
    mean_median_income_state_2018
)
SELECT * FROM state_us_mean_median_income_2018;


2021-02-15 16:58:26.654362 (Thread-1): finished collecting timing info
2021-02-15 16:58:26.656654 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '822a58f3-0a72-4ecb-a9d8-e14126092096', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10612edf0>]}
2021-02-15 16:58:26.658358 (Thread-1): 11:58:26 | 1 of 8 OK created view model dbt_shafali.acs_median_and_mean_US_and_states_2018 [OK in 1.55s]
2021-02-15 16:58:26.658660 (Thread-1): Finished running node model.dbt_income_project.acs_median_and_mean_US_and_states_2018
2021-02-15 16:58:26.659073 (Thread-1): Began running node model.dbt_income_project.acs_percentile_CA_2018
2021-02-15 16:58:26.660672 (Thread-1): 11:58:26 | 2 of 8 START view model dbt_shafali.acs_percentile_CA_2018........... [RUN]
2021-02-15 16:58:26.661474 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_CA_2018".
2021-02-15 16:58:26.661996 (Thread-1): Compiling model.dbt_income_project.acs_percentile_CA_2018
2021-02-15 16:58:26.683496 (Thread-1): Writing injected SQL for node "model.dbt_income_project.acs_percentile_CA_2018"
2021-02-15 16:58:26.685523 (Thread-1): finished collecting timing info
2021-02-15 16:58:26.713242 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.acs_percentile_CA_2018"
2021-02-15 16:58:26.714555 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 16:58:26.721442 (Thread-1): On model.dbt_income_project.acs_percentile_CA_2018: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.acs_percentile_CA_2018"} */


  create or replace view `dbt-income`.`dbt_shafali`.`acs_percentile_CA_2018`
  OPTIONS()
  as WITH acs_2018 AS (
    SELECT
        geo_id,
        median_income AS income_2018,
    FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
  ),

median_income_in_us_2018 AS(
 
    SELECT
    region, MAX(median) as median_income_in_US_2018
    FROM(
        SELECT "US" AS region,
        PERCENTILE_CONT( median_income, 0.5) 
            OVER ()AS median
        FROM bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr
    )
    AS tmp
    GROUP BY region
    
),

mean_income_in_us_2018 AS(
    SELECT 
     "US" AS region,AVG(median_income) AS mean_income_in_us_2018
     FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
),
acs_2018_with_statecode AS (
    SELECT
        geo_id,
        income_2018,
        geo.state_code
    FROM
        acs_2018 a18
    JOIN
        `bigquery-public-data.geo_us_boundaries.zip_codes` geo
    ON
        a18.geo_id = geo.zip_code 
    WHERE geo.state_code = 'NY' OR geo.state_code = 'CA' OR geo.state_code = 'TX' OR geo.state_code = 'FL'
),

median_income_state_2018 AS(
    SELECT
    state_code, MAX(median) as median_income_2018
    FROM(
        SELECT state_code,
        PERCENTILE_CONT( income_2018, 0.5) 
            OVER (PARTITION BY state_code)AS median
        FROM acs_2018_with_statecode
    )
    AS tmp
    GROUP BY state_code
),

mean_income_state_2018 AS(
    SELECT
    state_code,
     AVG(income_2018) AS mean_income_in_2018,

    FROM
    acs_2018_with_statecode
    
    GROUP BY
    state_code
),
 
mean_median_income_state_2018 AS(

    SELECT mean_income_state_2018.state_code, mean_income_in_2018, median_income_state_2018.median_income_2018 FROM mean_income_state_2018 
    INNER JOIN  median_income_state_2018 
    ON mean_income_state_2018.state_code = median_income_state_2018.state_code
 
),


mean_median_income_us_2018 AS(
    SELECT  median_income_in_us_2018.region,mean_income_in_us_2018.mean_income_in_US_2018, median_income_in_us_2018.median_income_in_US_2018 FROM median_income_in_us_2018 
    INNER JOIN  mean_income_in_us_2018  
    ON mean_income_in_us_2018.region = median_income_in_us_2018.region
 
)


SELECT  
  percentiles[offset(10)] as p10,
  percentiles[offset(25)] as p25,
  percentiles[offset(50)] as p50,
  percentiles[offset(75)] as p75,
  percentiles[offset(90)] as p90,
FROM (
  SELECT approx_quantiles(income_2018 , 100) percentiles
    FROM (
        SELECT state_code, income_2018 
        FROM acs_2018_with_statecode
        WHERE state_code = 'CA'
    ) AS income
);


2021-02-15 16:58:27.923886 (Thread-1): finished collecting timing info
2021-02-15 16:58:27.927296 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '822a58f3-0a72-4ecb-a9d8-e14126092096', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060524f0>]}
2021-02-15 16:58:27.932760 (Thread-1): 11:58:27 | 2 of 8 OK created view model dbt_shafali.acs_percentile_CA_2018...... [OK in 1.27s]
2021-02-15 16:58:27.933258 (Thread-1): Finished running node model.dbt_income_project.acs_percentile_CA_2018
2021-02-15 16:58:27.933728 (Thread-1): Began running node model.dbt_income_project.acs_percentile_FL_2018
2021-02-15 16:58:27.944382 (Thread-1): 11:58:27 | 3 of 8 START view model dbt_shafali.acs_percentile_FL_2018........... [RUN]
2021-02-15 16:58:27.947515 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_FL_2018".
2021-02-15 16:58:27.949264 (Thread-1): Compiling model.dbt_income_project.acs_percentile_FL_2018
2021-02-15 16:58:28.023886 (Thread-1): Writing injected SQL for node "model.dbt_income_project.acs_percentile_FL_2018"
2021-02-15 16:58:28.028040 (Thread-1): finished collecting timing info
2021-02-15 16:58:28.057108 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.acs_percentile_FL_2018"
2021-02-15 16:58:28.058071 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 16:58:28.073098 (Thread-1): On model.dbt_income_project.acs_percentile_FL_2018: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.acs_percentile_FL_2018"} */


  create or replace view `dbt-income`.`dbt_shafali`.`acs_percentile_FL_2018`
  OPTIONS()
  as WITH acs_2018 AS (
    SELECT
        geo_id,
        median_income AS income_2018,
    FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
  ),

median_income_in_us_2018 AS(
 
    SELECT
    region, MAX(median) as median_income_in_US_2018
    FROM(
        SELECT "US" AS region,
        PERCENTILE_CONT( median_income, 0.5) 
            OVER ()AS median
        FROM bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr
    )
    AS tmp
    GROUP BY region
    
),

mean_income_in_us_2018 AS(
    SELECT 
     "US" AS region,AVG(median_income) AS mean_income_in_us_2018
     FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
),
acs_2018_with_statecode AS (
    SELECT
        geo_id,
        income_2018,
        geo.state_code
    FROM
        acs_2018 a18
    JOIN
        `bigquery-public-data.geo_us_boundaries.zip_codes` geo
    ON
        a18.geo_id = geo.zip_code 
    WHERE geo.state_code = 'NY' OR geo.state_code = 'CA' OR geo.state_code = 'TX' OR geo.state_code = 'FL'
),

median_income_state_2018 AS(
    SELECT
    state_code, MAX(median) as median_income_2018
    FROM(
        SELECT state_code,
        PERCENTILE_CONT( income_2018, 0.5) 
            OVER (PARTITION BY state_code)AS median
        FROM acs_2018_with_statecode
    )
    AS tmp
    GROUP BY state_code
),

mean_income_state_2018 AS(
    SELECT
    state_code,
     AVG(income_2018) AS mean_income_in_2018,

    FROM
    acs_2018_with_statecode
    
    GROUP BY
    state_code
),
 
mean_median_income_state_2018 AS(

    SELECT mean_income_state_2018.state_code, mean_income_in_2018, median_income_state_2018.median_income_2018 FROM mean_income_state_2018 
    INNER JOIN  median_income_state_2018 
    ON mean_income_state_2018.state_code = median_income_state_2018.state_code
 
),


mean_median_income_us_2018 AS(
    SELECT  median_income_in_us_2018.region,mean_income_in_us_2018.mean_income_in_US_2018, median_income_in_us_2018.median_income_in_US_2018 FROM median_income_in_us_2018 
    INNER JOIN  mean_income_in_us_2018  
    ON mean_income_in_us_2018.region = median_income_in_us_2018.region
 
)


SELECT  
  percentiles[offset(10)] as p10,
  percentiles[offset(25)] as p25,
  percentiles[offset(50)] as p50,
  percentiles[offset(75)] as p75,
  percentiles[offset(90)] as p90,
FROM (
  SELECT approx_quantiles(income_2018 , 100) percentiles
    FROM (
        SELECT state_code, income_2018 
        FROM acs_2018_with_statecode
        WHERE state_code = 'FL'
    ) AS income
);


2021-02-15 16:58:29.428725 (Thread-1): finished collecting timing info
2021-02-15 16:58:29.439524 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '822a58f3-0a72-4ecb-a9d8-e14126092096', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060fd070>]}
2021-02-15 16:58:29.446779 (Thread-1): 11:58:29 | 3 of 8 OK created view model dbt_shafali.acs_percentile_FL_2018...... [OK in 1.49s]
2021-02-15 16:58:29.447359 (Thread-1): Finished running node model.dbt_income_project.acs_percentile_FL_2018
2021-02-15 16:58:29.451162 (Thread-1): Began running node model.dbt_income_project.acs_percentile_NY_2018
2021-02-15 16:58:29.455478 (Thread-1): 11:58:29 | 4 of 8 START view model dbt_shafali.acs_percentile_NY_2018........... [RUN]
2021-02-15 16:58:29.456408 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_NY_2018".
2021-02-15 16:58:29.456709 (Thread-1): Compiling model.dbt_income_project.acs_percentile_NY_2018
2021-02-15 16:58:29.491857 (Thread-1): Writing injected SQL for node "model.dbt_income_project.acs_percentile_NY_2018"
2021-02-15 16:58:29.493138 (Thread-1): finished collecting timing info
2021-02-15 16:58:29.525150 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.acs_percentile_NY_2018"
2021-02-15 16:58:29.526248 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 16:58:29.543192 (Thread-1): On model.dbt_income_project.acs_percentile_NY_2018: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.acs_percentile_NY_2018"} */


  create or replace view `dbt-income`.`dbt_shafali`.`acs_percentile_NY_2018`
  OPTIONS()
  as WITH acs_2018 AS (
    SELECT
        geo_id,
        median_income AS income_2018,
    FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
  ),

median_income_in_us_2018 AS(
 
    SELECT
    region, MAX(median) as median_income_in_US_2018
    FROM(
        SELECT "US" AS region,
        PERCENTILE_CONT( median_income, 0.5) 
            OVER ()AS median
        FROM bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr
    )
    AS tmp
    GROUP BY region
    
),

mean_income_in_us_2018 AS(
    SELECT 
     "US" AS region,AVG(median_income) AS mean_income_in_us_2018
     FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
),
acs_2018_with_statecode AS (
    SELECT
        geo_id,
        income_2018,
        geo.state_code
    FROM
        acs_2018 a18
    JOIN
        `bigquery-public-data.geo_us_boundaries.zip_codes` geo
    ON
        a18.geo_id = geo.zip_code 
    WHERE geo.state_code = 'NY' OR geo.state_code = 'CA' OR geo.state_code = 'TX' OR geo.state_code = 'FL'
),

median_income_state_2018 AS(
    SELECT
    state_code, MAX(median) as median_income_2018
    FROM(
        SELECT state_code,
        PERCENTILE_CONT( income_2018, 0.5) 
            OVER (PARTITION BY state_code)AS median
        FROM acs_2018_with_statecode
    )
    AS tmp
    GROUP BY state_code
),

mean_income_state_2018 AS(
    SELECT
    state_code,
     AVG(income_2018) AS mean_income_in_2018,

    FROM
    acs_2018_with_statecode
    
    GROUP BY
    state_code
),
 
mean_median_income_state_2018 AS(

    SELECT mean_income_state_2018.state_code, mean_income_in_2018, median_income_state_2018.median_income_2018 FROM mean_income_state_2018 
    INNER JOIN  median_income_state_2018 
    ON mean_income_state_2018.state_code = median_income_state_2018.state_code
 
),


mean_median_income_us_2018 AS(
    SELECT  median_income_in_us_2018.region,mean_income_in_us_2018.mean_income_in_US_2018, median_income_in_us_2018.median_income_in_US_2018 FROM median_income_in_us_2018 
    INNER JOIN  mean_income_in_us_2018  
    ON mean_income_in_us_2018.region = median_income_in_us_2018.region
 
)


SELECT  
  percentiles[offset(10)] as p10,
  percentiles[offset(25)] as p25,
  percentiles[offset(50)] as p50,
  percentiles[offset(75)] as p75,
  percentiles[offset(90)] as p90,
FROM (
  SELECT approx_quantiles(income_2018 , 100) percentiles
    FROM (
        SELECT state_code, income_2018 
        FROM acs_2018_with_statecode
        WHERE state_code = 'NY'
    ) AS income
);


2021-02-15 16:58:31.688109 (Thread-1): finished collecting timing info
2021-02-15 16:58:31.688978 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '822a58f3-0a72-4ecb-a9d8-e14126092096', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10612edf0>]}
2021-02-15 16:58:31.691310 (Thread-1): 11:58:31 | 4 of 8 OK created view model dbt_shafali.acs_percentile_NY_2018...... [OK in 2.23s]
2021-02-15 16:58:31.691741 (Thread-1): Finished running node model.dbt_income_project.acs_percentile_NY_2018
2021-02-15 16:58:31.692179 (Thread-1): Began running node model.dbt_income_project.acs_percentile_TX_2018
2021-02-15 16:58:31.693815 (Thread-1): 11:58:31 | 5 of 8 START view model dbt_shafali.acs_percentile_TX_2018........... [RUN]
2021-02-15 16:58:31.694344 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_TX_2018".
2021-02-15 16:58:31.694516 (Thread-1): Compiling model.dbt_income_project.acs_percentile_TX_2018
2021-02-15 16:58:31.703355 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 53706), raddr=('172.217.6.202', 443)>
2021-02-15 16:58:31.704077 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 53707), raddr=('172.217.3.106', 443)>
2021-02-15 16:58:31.705544 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 53708), raddr=('172.217.6.202', 443)>
2021-02-15 16:58:31.706171 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 53709), raddr=('172.217.3.106', 443)>
2021-02-15 16:58:31.706695 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 53711), raddr=('172.217.3.106', 443)>
2021-02-15 16:58:31.707157 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 53710), raddr=('172.217.6.202', 443)>
2021-02-15 16:58:31.707672 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 53713), raddr=('172.217.6.202', 443)>
2021-02-15 16:58:31.708324 (Thread-1): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 53714), raddr=('172.217.3.106', 443)>
2021-02-15 16:58:31.723662 (Thread-1): Writing injected SQL for node "model.dbt_income_project.acs_percentile_TX_2018"
2021-02-15 16:58:31.724449 (Thread-1): finished collecting timing info
2021-02-15 16:58:31.733513 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.acs_percentile_TX_2018"
2021-02-15 16:58:31.737307 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 16:58:31.744166 (Thread-1): On model.dbt_income_project.acs_percentile_TX_2018: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.acs_percentile_TX_2018"} */


  create or replace view `dbt-income`.`dbt_shafali`.`acs_percentile_TX_2018`
  OPTIONS()
  as WITH acs_2018 AS (
    SELECT
        geo_id,
        median_income AS income_2018,
    FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
  ),

median_income_in_us_2018 AS(
 
    SELECT
    region, MAX(median) as median_income_in_US_2018
    FROM(
        SELECT "US" AS region,
        PERCENTILE_CONT( median_income, 0.5) 
            OVER ()AS median
        FROM bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr
    )
    AS tmp
    GROUP BY region
    
),

mean_income_in_us_2018 AS(
    SELECT 
     "US" AS region,AVG(median_income) AS mean_income_in_us_2018
     FROM
        `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
),
acs_2018_with_statecode AS (
    SELECT
        geo_id,
        income_2018,
        geo.state_code
    FROM
        acs_2018 a18
    JOIN
        `bigquery-public-data.geo_us_boundaries.zip_codes` geo
    ON
        a18.geo_id = geo.zip_code 
    WHERE geo.state_code = 'NY' OR geo.state_code = 'CA' OR geo.state_code = 'TX' OR geo.state_code = 'FL'
),

median_income_state_2018 AS(
    SELECT
    state_code, MAX(median) as median_income_2018
    FROM(
        SELECT state_code,
        PERCENTILE_CONT( income_2018, 0.5) 
            OVER (PARTITION BY state_code)AS median
        FROM acs_2018_with_statecode
    )
    AS tmp
    GROUP BY state_code
),

mean_income_state_2018 AS(
    SELECT
    state_code,
     AVG(income_2018) AS mean_income_in_2018,

    FROM
    acs_2018_with_statecode
    
    GROUP BY
    state_code
),
 
mean_median_income_state_2018 AS(

    SELECT mean_income_state_2018.state_code, mean_income_in_2018, median_income_state_2018.median_income_2018 FROM mean_income_state_2018 
    INNER JOIN  median_income_state_2018 
    ON mean_income_state_2018.state_code = median_income_state_2018.state_code
 
),


mean_median_income_us_2018 AS(
    SELECT  median_income_in_us_2018.region,mean_income_in_us_2018.mean_income_in_US_2018, median_income_in_us_2018.median_income_in_US_2018 FROM median_income_in_us_2018 
    INNER JOIN  mean_income_in_us_2018  
    ON mean_income_in_us_2018.region = median_income_in_us_2018.region
 
)


SELECT  
  percentiles[offset(10)] as p10,
  percentiles[offset(25)] as p25,
  percentiles[offset(50)] as p50,
  percentiles[offset(75)] as p75,
  percentiles[offset(90)] as p90,
FROM (
  SELECT approx_quantiles(income_2018 , 100) percentiles
    FROM (
        SELECT state_code, income_2018 
        FROM acs_2018_with_statecode
        WHERE state_code = 'TX'
    ) AS income
);


2021-02-15 16:58:32.874813 (Thread-1): finished collecting timing info
2021-02-15 16:58:32.877444 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '822a58f3-0a72-4ecb-a9d8-e14126092096', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106215550>]}
2021-02-15 16:58:32.883293 (Thread-1): 11:58:32 | 5 of 8 OK created view model dbt_shafali.acs_percentile_TX_2018...... [OK in 1.18s]
2021-02-15 16:58:32.883664 (Thread-1): Finished running node model.dbt_income_project.acs_percentile_TX_2018
2021-02-15 16:58:32.883999 (Thread-1): Began running node model.dbt_income_project.acs_percentile_US_2018
2021-02-15 16:58:32.887686 (Thread-1): 11:58:32 | 6 of 8 START view model dbt_shafali.acs_percentile_US_2018........... [RUN]
2021-02-15 16:58:32.888470 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_US_2018".
2021-02-15 16:58:32.888737 (Thread-1): Compiling model.dbt_income_project.acs_percentile_US_2018
2021-02-15 16:58:32.901535 (Thread-1): Writing injected SQL for node "model.dbt_income_project.acs_percentile_US_2018"
2021-02-15 16:58:32.903755 (Thread-1): finished collecting timing info
2021-02-15 16:58:32.920721 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.acs_percentile_US_2018"
2021-02-15 16:58:32.923563 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 16:58:32.936334 (Thread-1): On model.dbt_income_project.acs_percentile_US_2018: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.acs_percentile_US_2018"} */


  create or replace view `dbt-income`.`dbt_shafali`.`acs_percentile_US_2018`
  OPTIONS()
  as SELECT  
  percentiles[offset(10)] as p10,
  percentiles[offset(25)] as p25,
  percentiles[offset(50)] as p50,
  percentiles[offset(75)] as p75,
  percentiles[offset(90)] as p90,
from (
  select approx_quantiles(median_income, 100) percentiles
  from  `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr` 
);


2021-02-15 16:58:33.872331 (Thread-1): finished collecting timing info
2021-02-15 16:58:33.876683 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '822a58f3-0a72-4ecb-a9d8-e14126092096', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10606c970>]}
2021-02-15 16:58:33.885151 (Thread-1): 11:58:33 | 6 of 8 OK created view model dbt_shafali.acs_percentile_US_2018...... [OK in 0.99s]
2021-02-15 16:58:33.885639 (Thread-1): Finished running node model.dbt_income_project.acs_percentile_US_2018
2021-02-15 16:58:33.886152 (Thread-1): Began running node model.dbt_income_project.mean_median_US_2013_2018
2021-02-15 16:58:33.892004 (Thread-1): 11:58:33 | 7 of 8 START view model dbt_shafali.mean_median_US_2013_2018......... [RUN]
2021-02-15 16:58:33.893796 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.mean_median_US_2013_2018".
2021-02-15 16:58:33.894223 (Thread-1): Compiling model.dbt_income_project.mean_median_US_2013_2018
2021-02-15 16:58:33.908353 (Thread-1): Writing injected SQL for node "model.dbt_income_project.mean_median_US_2013_2018"
2021-02-15 16:58:33.909636 (Thread-1): finished collecting timing info
2021-02-15 16:58:33.924177 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.mean_median_US_2013_2018"
2021-02-15 16:58:33.924982 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 16:58:33.934445 (Thread-1): On model.dbt_income_project.mean_median_US_2013_2018: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.mean_median_US_2013_2018"} */


  create or replace view `dbt-income`.`dbt_shafali`.`mean_median_US_2013_2018`
  OPTIONS()
  as WITH 
acs_2013 AS (
  SELECT geo_id, median_income AS income_2013
  FROM `bigquery-public-data.census_bureau_acs.zip_codes_2013_5yr`  
),
acs_2018 AS (
  SELECT geo_id, median_income AS income_2018
  FROM `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr`  
), 
acs_2013_2018 AS(
    SELECT acs_2013.geo_id, income_2013, income_2018
    FROM 
    acs_2013 
    FULL JOIN 
    acs_2018
    ON 
    acs_2013.geo_id =acs_2018.geo_id
),
# mean
mean_income_2013_2018 AS( 
    SELECT "2013-2018"AS years, AVG(income_2013) AS mean_income_2013, AVG(income_2018)AS mean_income_2018
    FROM acs_2013_2018
),
# median 
median_income_2013_2018 AS( 
    SELECT "2013-2018"AS years, PERCENTILE_CONT(income_2013, 0.5) OVER() AS median_income_2013,
    PERCENTILE_CONT(income_2018, 0.5) OVER() AS median_income_2018
    FROM acs_2013_2018
    LIMIT 1
),
# median+mean
mean_median_income_2013_2018 AS(
    SELECT mean.years, mean_income_2013, median_income_2013,mean_income_2018, median_income_2018 
    FROM (
      mean_income_2013_2018 mean
      JOIN 
      median_income_2013_2018 median
      ON 
      mean.years = median.years
    )
)
SELECT * FROM mean_median_income_2013_2018;


2021-02-15 16:58:35.160256 (Thread-1): finished collecting timing info
2021-02-15 16:58:35.161456 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '822a58f3-0a72-4ecb-a9d8-e14126092096', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060f5070>]}
2021-02-15 16:58:35.164566 (Thread-1): 11:58:35 | 7 of 8 OK created view model dbt_shafali.mean_median_US_2013_2018.... [OK in 1.27s]
2021-02-15 16:58:35.166073 (Thread-1): Finished running node model.dbt_income_project.mean_median_US_2013_2018
2021-02-15 16:58:35.167426 (Thread-1): Began running node model.dbt_income_project.percentile_2013_2018
2021-02-15 16:58:35.172545 (Thread-1): 11:58:35 | 8 of 8 START view model dbt_shafali.percentile_2013_2018............. [RUN]
2021-02-15 16:58:35.173316 (Thread-1): Acquiring new bigquery connection "model.dbt_income_project.percentile_2013_2018".
2021-02-15 16:58:35.173697 (Thread-1): Compiling model.dbt_income_project.percentile_2013_2018
2021-02-15 16:58:35.192430 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 53720), raddr=('172.217.6.202', 443)>
2021-02-15 16:58:35.193254 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 53721), raddr=('172.217.3.106', 443)>
2021-02-15 16:58:35.225493 (Thread-1): Writing injected SQL for node "model.dbt_income_project.percentile_2013_2018"
2021-02-15 16:58:35.226508 (Thread-1): finished collecting timing info
2021-02-15 16:58:35.247225 (Thread-1): Writing runtime SQL for node "model.dbt_income_project.percentile_2013_2018"
2021-02-15 16:58:35.284591 (Thread-1): Opening a new connection, currently in state closed
2021-02-15 16:58:35.296189 (Thread-1): On model.dbt_income_project.percentile_2013_2018: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "dbt_income_project", "target_name": "dev", "node_id": "model.dbt_income_project.percentile_2013_2018"} */


  create or replace view `dbt-income`.`dbt_shafali`.`percentile_2013_2018`
  OPTIONS()
  as WITH 
acs_2013 AS (
  SELECT geo_id, median_income AS income_2013
  FROM `bigquery-public-data.census_bureau_acs.zip_codes_2013_5yr`  
),
acs_2018 AS (
  SELECT  geo_id, median_income AS income_2018
  FROM `bigquery-public-data.census_bureau_acs.zip_codes_2018_5yr`  
), 
acs_2013_2018 AS(
    SELECT  acs_2013.geo_id, income_2013, income_2018
    FROM 
    acs_2013 
    FULL JOIN 
    acs_2018
    ON 
    acs_2013.geo_id =acs_2018.geo_id
),
percentiles_2013 AS(
  SELECT  
    "2013" as year,
    percentiles[offset(10)] as p10,
    percentiles[offset(25)] as p25,
    percentiles[offset(50)] as p50,
    percentiles[offset(75)] as p75,
    percentiles[offset(90)] as p90,
  from (
    select approx_quantiles(income_2013, 100) percentiles
    from  acs_2013_2018
  )
),
percentiles_2018 AS(
  SELECT  
    "2018" as year,
    percentiles[offset(10)] as p10,
    percentiles[offset(25)] as p25,
    percentiles[offset(50)] as p50,
    percentiles[offset(75)] as p75,
    percentiles[offset(90)] as p90,
  from (
    select approx_quantiles(income_2018, 100) percentiles
    from  acs_2013_2018
  )
)

SELECT * FROM 
  (
    SELECT year, p10, p25, p50, p75, p90
    FROM 
    percentiles_2013
    UNION ALL
    SELECT year, p10, p25, p50, p75, p90 
    FROM percentiles_2018
  ) percentiles_2013_2018;


2021-02-15 16:58:36.762012 (Thread-1): finished collecting timing info
2021-02-15 16:58:36.766372 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '822a58f3-0a72-4ecb-a9d8-e14126092096', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10612edf0>]}
2021-02-15 16:58:36.774070 (Thread-1): 11:58:36 | 8 of 8 OK created view model dbt_shafali.percentile_2013_2018........ [OK in 1.59s]
2021-02-15 16:58:36.774741 (Thread-1): Finished running node model.dbt_income_project.percentile_2013_2018
2021-02-15 16:58:36.783657 (MainThread): Acquiring new bigquery connection "master".
2021-02-15 16:58:36.784510 (MainThread): 11:58:36 | 
2021-02-15 16:58:36.784834 (MainThread): 11:58:36 | Finished running 8 view models in 13.24s.
2021-02-15 16:58:36.785120 (MainThread): Connection 'master' was properly closed.
2021-02-15 16:58:36.785273 (MainThread): Connection 'model.dbt_income_project.percentile_2013_2018' was properly closed.
2021-02-15 16:58:37.002782 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 53715), raddr=('172.217.6.202', 443)>
2021-02-15 16:58:37.003987 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 53716), raddr=('172.217.3.106', 443)>
2021-02-15 16:58:37.005375 (MainThread): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 53718), raddr=('172.217.3.106', 443)>
2021-02-15 16:58:37.007415 (MainThread): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 53717), raddr=('172.217.6.202', 443)>
2021-02-15 16:58:37.022345 (MainThread): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 53722), raddr=('172.217.6.202', 443)>
2021-02-15 16:58:37.023449 (MainThread): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.151', 53723), raddr=('172.217.3.106', 443)>
2021-02-15 16:58:37.301865 (MainThread): 
2021-02-15 16:58:37.302339 (MainThread): Completed successfully
2021-02-15 16:58:37.309157 (MainThread): 
Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
2021-02-15 16:58:37.323697 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10610f160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10610f130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062a96d0>]}
2021-02-15 16:58:37.324376 (MainThread): Flushing usage events
2021-02-15 16:58:57.396060 (MainThread): Running with dbt=0.19.0
2021-02-15 16:59:11.570231 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.deps.DepsTask'>, debug=False, defer=None, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/shafaligupta/.dbt', project_dir=None, record_timing_info=None, rpc_method='deps', single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, use_cache=True, use_colors=None, vars='{}', warn_error=False, which='deps', write_json=True)
2021-02-15 16:59:11.573740 (MainThread): Tracking: tracking
2021-02-15 16:59:11.617203 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cc5df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ce2760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ce20a0>]}
2021-02-15 16:59:11.619558 (MainThread): Warning: No packages were found in packages.yml
2021-02-15 16:59:11.620384 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cc5df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ce2760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ce20a0>]}
2021-02-15 16:59:11.620957 (MainThread): Flushing usage events
2021-02-15 17:00:58.500053 (MainThread): Running with dbt=0.19.0
2021-02-15 17:01:01.686881 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/shafaligupta/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-02-15 17:01:01.695653 (MainThread): Tracking: tracking
2021-02-15 17:01:01.721691 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a29640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a36eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a36d90>]}
2021-02-15 17:01:01.900777 (MainThread): Partial parsing not enabled
2021-02-15 17:01:01.911728 (MainThread): Parsing macros/etc.sql
2021-02-15 17:01:01.973355 (MainThread): Parsing macros/catalog.sql
2021-02-15 17:01:02.170569 (MainThread): Parsing macros/adapters.sql
2021-02-15 17:01:02.377034 (MainThread): Parsing macros/materializations/seed.sql
2021-02-15 17:01:02.390537 (MainThread): Parsing macros/materializations/view.sql
2021-02-15 17:01:02.421664 (MainThread): Parsing macros/materializations/table.sql
2021-02-15 17:01:02.487409 (MainThread): Parsing macros/materializations/copy.sql
2021-02-15 17:01:02.507582 (MainThread): Parsing macros/materializations/incremental.sql
2021-02-15 17:01:02.576656 (MainThread): Parsing macros/materializations/snapshot.sql
2021-02-15 17:01:02.589690 (MainThread): Parsing macros/core.sql
2021-02-15 17:01:02.607669 (MainThread): Parsing macros/materializations/helpers.sql
2021-02-15 17:01:02.651725 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-02-15 17:01:02.660717 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-02-15 17:01:02.707226 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-02-15 17:01:02.834809 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-02-15 17:01:02.936790 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-02-15 17:01:02.949554 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-02-15 17:01:02.970597 (MainThread): Parsing macros/materializations/common/merge.sql
2021-02-15 17:01:03.013263 (MainThread): Parsing macros/materializations/table/table.sql
2021-02-15 17:01:03.039166 (MainThread): Parsing macros/materializations/view/view.sql
2021-02-15 17:01:03.073433 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-02-15 17:01:03.089618 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-02-15 17:01:03.092738 (MainThread): Parsing macros/etc/query.sql
2021-02-15 17:01:03.102006 (MainThread): Parsing macros/etc/is_incremental.sql
2021-02-15 17:01:03.110244 (MainThread): Parsing macros/etc/datetime.sql
2021-02-15 17:01:03.148454 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-02-15 17:01:03.182234 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-02-15 17:01:03.188620 (MainThread): Parsing macros/adapters/common.sql
2021-02-15 17:01:03.735626 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-02-15 17:01:03.740757 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-02-15 17:01:03.748474 (MainThread): Parsing macros/schema_tests/unique.sql
2021-02-15 17:01:03.753697 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-02-15 17:01:03.787354 (MainThread): Partial parsing not enabled
2021-02-15 17:01:04.633973 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.percentile_2013_2018".
2021-02-15 17:01:04.863724 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.mean_median_US_2013_2018".
2021-02-15 17:01:04.905274 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_US_2018".
2021-02-15 17:01:04.945788 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_FL_2018".
2021-02-15 17:01:05.207708 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_median_and_mean_US_and_states_2018".
2021-02-15 17:01:05.262366 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_TX_2018".
2021-02-15 17:01:05.300091 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_CA_2018".
2021-02-15 17:01:05.449857 (MainThread): Acquiring new bigquery connection "model.dbt_income_project.acs_percentile_NY_2018".
2021-02-15 17:01:05.883077 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4a66c7f6-2de5-47d5-b6e3-50d893aa18fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c01b50>]}
2021-02-15 17:01:06.020326 (MainThread): Found 8 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-02-15 17:01:06.021931 (MainThread): WARNING: Nothing to do. Try checking your model configs and model specification args
2021-02-15 17:01:06.022938 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d33730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105aa6be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c574f0>]}
2021-02-15 17:01:06.023670 (MainThread): Flushing usage events
2021-02-15 17:01:06.578662 (MainThread): Connection 'model.dbt_income_project.acs_percentile_NY_2018' was properly closed.
